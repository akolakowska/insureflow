{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import asyncio\n",
    "import nest_asyncio  # Important for running asyncio in Jupyter notebooks\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# LlamaIndex imports\n",
    "from llama_index.core import Settings, VectorStoreIndex, Document\n",
    "from llama_index.core.agent.workflow import FunctionAgent, AgentWorkflow\n",
    "from llama_index.core.workflow import Context, InputRequiredEvent, HumanResponseEvent\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "# Apply nest_asyncio to allow asyncio to work in Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"InsuranceAgentSystem\")\n",
    "\n",
    "# Environment variables - in production, load these from environment\n",
    "AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY', 'your-api-key')\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT', 'your-endpoint')\n",
    "AZURE_GPT_API_VERSION = os.getenv('AZURE_GPT_API_VERSION', '2025-01-01-preview')\n",
    "AZURE_EMBEDDING_API_VERSION = os.getenv('AZURE_EMBEDDING_API_VERSION', '2023-12-01-preview')\n",
    "\n",
    "class InsuranceAgentSystem:\n",
    "    \"\"\"Main class for the Insurance Agent System implementing Stage 4 (Rank or Reject)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the system with LLM, embeddings and guidelines\"\"\"\n",
    "        self.setup_llm_and_embeddings()\n",
    "        self.setup_guidelines_vector_store()\n",
    "        self.create_agents()\n",
    "        \n",
    "    def setup_llm_and_embeddings(self):\n",
    "        \"\"\"Configure the LLM and embedding models\"\"\"\n",
    "        self.llm = AzureOpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            deployment_name=\"gpt-4o\",\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            api_version=AZURE_GPT_API_VERSION,\n",
    "            temperature=0.1,  # Lower temperature for consistent decisions\n",
    "            timeout=60,\n",
    "        )\n",
    "        \n",
    "        self.embed_model = AzureOpenAIEmbedding(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            deployment_name=\"text-embedding-ada-002\",\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            api_version=AZURE_EMBEDDING_API_VERSION,\n",
    "        )\n",
    "        \n",
    "        # Set as default models\n",
    "        Settings.llm = self.llm\n",
    "        Settings.embed_model = self.embed_model\n",
    "        \n",
    "        logger.info(\"LLM and embedding models initialized\")\n",
    "    \n",
    "    def setup_guidelines_vector_store(self):\n",
    "        \"\"\"Load the underwriting guidelines and create a vector store\"\"\"\n",
    "        try:\n",
    "            # Load guidelines from file\n",
    "            with open('underwriting_guidelines.json', 'r') as file:\n",
    "                guidelines_data = json.load(file)\n",
    "            \n",
    "            # Convert to text format for embedding\n",
    "            guidelines_text = json.dumps(guidelines_data, indent=2)\n",
    "            \n",
    "            # Create document\n",
    "            guidelines_doc = Document(text=guidelines_text, metadata={\"source\": \"underwriting_guidelines\"})\n",
    "            \n",
    "            # Create vector store index\n",
    "            self.guidelines_index = VectorStoreIndex.from_documents([guidelines_doc])\n",
    "            \n",
    "            # Create retriever for semantic search\n",
    "            self.guidelines_retriever = self.guidelines_index.as_retriever(\n",
    "                similarity_top_k=3\n",
    "            )\n",
    "            \n",
    "            logger.info(\"Guidelines vector store initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error setting up guidelines vector store: {str(e)}\")\n",
    "            # Fallback to mock data if file not found\n",
    "            self.guidelines_index = None\n",
    "            self.guidelines_retriever = None\n",
    "            logger.warning(\"Using mock guidelines data as fallback\")\n",
    "    \n",
    "    def create_agents(self):\n",
    "        \"\"\"Create all the specialized agents for the workflow\"\"\"\n",
    "        # The actual agent creation happens at the end of this method to keep all tools in scope\n",
    "        # Create all the agents with their tools\n",
    "        \n",
    "        # Hazard Agent Tools\n",
    "        async def evaluate_hazard_classification(ctx: Context, property_data: Dict[str, Any]) -> str:\n",
    "            \"\"\"\n",
    "            Evaluates the hazard classification of a property based on building type, \n",
    "            construction materials, and occupancy.\n",
    "            \n",
    "            Args:\n",
    "                property_data: Dictionary containing property details\n",
    "                \n",
    "            Returns:\n",
    "                A description of the hazard assessment with score (1-5)\n",
    "            \"\"\"\n",
    "            logger.info(\"Starting hazard classification assessment\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            \n",
    "            # Simulate hazard classification logic\n",
    "            building_type = property_data.get(\"building_type\", \"\")\n",
    "            construction = property_data.get(\"construction\", \"\")\n",
    "            occupancy = property_data.get(\"occupancy\", \"\")\n",
    "            \n",
    "            logger.info(f\"Analyzing property: {building_type} building with {construction} construction\")\n",
    "            \n",
    "            # Sample logic - would be more sophisticated in production\n",
    "            hazard_factors = {\n",
    "                \"building_type\": {\n",
    "                    \"Office\": 1,\n",
    "                    \"Retail\": 2,\n",
    "                    \"Manufacturing\": 3,\n",
    "                    \"Warehouse\": 3,\n",
    "                    \"Heavy Industrial\": 4,\n",
    "                    \"Nightclub\": 5\n",
    "                },\n",
    "                \"construction\": {\n",
    "                    \"Concrete\": 1,\n",
    "                    \"Steel Frame\": 2,\n",
    "                    \"Brick\": 2,\n",
    "                    \"Wood Frame\": 4,\n",
    "                    \"Mixed\": 3\n",
    "                }\n",
    "            }\n",
    "\n",
    "            bt_score = hazard_factors[\"building_type\"].get(building_type, 3)\n",
    "            const_score = 3  # Default score\n",
    "            for material, score in hazard_factors[\"construction\"].items():\n",
    "                if material.lower() in construction.lower():\n",
    "                    const_score = score\n",
    "                    break\n",
    "\n",
    "            # Calculate overall hazard score\n",
    "            hazard_score = (bt_score + const_score) / 2\n",
    "            logger.info(f\"Calculated hazard score: {hazard_score}\")\n",
    "            \n",
    "            # Store the result in context\n",
    "            if \"assessment_results\" not in current_state:\n",
    "                current_state[\"assessment_results\"] = {}\n",
    "            \n",
    "            current_state[\"assessment_results\"][\"hazard\"] = {\n",
    "                \"score\": hazard_score,\n",
    "                \"building_type_assessment\": f\"{building_type}: Risk level {bt_score}\",\n",
    "                \"construction_assessment\": f\"{construction}: Risk level {const_score}\",\n",
    "                \"occupancy_details\": occupancy\n",
    "            }\n",
    "            \n",
    "            # Track completion as a list\n",
    "            if \"completed_assessments\" not in current_state:\n",
    "                current_state[\"completed_assessments\"] = []\n",
    "                \n",
    "            if \"hazard\" not in current_state[\"completed_assessments\"]:\n",
    "                current_state[\"completed_assessments\"].append(\"hazard\")\n",
    "            \n",
    "            logger.info(f\"Updated completed_assessments: {current_state['completed_assessments']}\")\n",
    "            await ctx.set(\"state\", current_state)\n",
    "            \n",
    "            logger.info(\"Hazard assessment completed and stored in context\")\n",
    "            return f\"Hazard assessment completed. Overall hazard score: {hazard_score:.1f}/5.0\"\n",
    "        \n",
    "        async def query_hazard_guidelines(ctx: Context, query: str) -> str:\n",
    "            \"\"\"\n",
    "            Queries the underwriting guidelines for hazard-related information.\n",
    "            \n",
    "            Args:\n",
    "                query: The search query for hazard-related guidelines\n",
    "                \n",
    "            Returns:\n",
    "                Relevant guidelines information\n",
    "            \"\"\"\n",
    "            logger.info(f\"Querying hazard guidelines with: {query}\")\n",
    "            \n",
    "            if self.guidelines_retriever is None:\n",
    "                return \"Guidelines retriever not available. Using default guidelines.\"\n",
    "            \n",
    "            try:\n",
    "                # Query the vector store\n",
    "                retrieval_results = self.guidelines_retriever.retrieve(query)\n",
    "                \n",
    "                # Extract and format the results\n",
    "                guidelines_info = \"\\n\\n\".join([node.text for node in retrieval_results])\n",
    "                \n",
    "                # Store in context\n",
    "                current_state = await ctx.get(\"state\")\n",
    "                if \"guidelines_retrieved\" not in current_state:\n",
    "                    current_state[\"guidelines_retrieved\"] = {}\n",
    "                \n",
    "                current_state[\"guidelines_retrieved\"][\"hazard\"] = guidelines_info\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"Successfully retrieved hazard guidelines\")\n",
    "                return f\"Retrieved hazard guidelines: {guidelines_info}\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error querying hazard guidelines: {str(e)}\")\n",
    "                return \"Error retrieving hazard guidelines. Using default assessment only.\"\n",
    "        \n",
    "        # Vulnerability Agent Tools\n",
    "        async def evaluate_vulnerability(ctx: Context, security_data: Dict[str, Any]) -> str:\n",
    "            \"\"\"\n",
    "            Evaluates the vulnerability of a property based on security systems,\n",
    "            protective measures, and other safety features.\n",
    "            \n",
    "            Args:\n",
    "                security_data: Dictionary containing security details\n",
    "                \n",
    "            Returns:\n",
    "                A description of the vulnerability assessment with score (1-5)\n",
    "            \"\"\"\n",
    "            logger.info(\"Starting vulnerability assessment\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            \n",
    "            # Simulate vulnerability assessment\n",
    "            has_sprinklers = security_data.get(\"sprinklers\", False)\n",
    "            alarm_system = security_data.get(\"alarm_system\", \"None\")\n",
    "            \n",
    "            logger.info(f\"Security features: Sprinklers={has_sprinklers}, Alarm={alarm_system}\")\n",
    "            \n",
    "            # Basic scoring\n",
    "            sprinkler_score = 1 if has_sprinklers else 4\n",
    "            \n",
    "            alarm_scores = {\n",
    "                \"None\": 5,\n",
    "                \"Local\": 3,\n",
    "                \"Monitored\": 2,\n",
    "                \"Grade A - 24hr Monitored\": 1\n",
    "            }\n",
    "            alarm_score = alarm_scores.get(alarm_system, 3)\n",
    "            \n",
    "            # Calculate overall vulnerability score\n",
    "            vulnerability_score = (sprinkler_score + alarm_score) / 2\n",
    "            logger.info(f\"Calculated vulnerability score: {vulnerability_score}\")\n",
    "\n",
    "            # Store the result\n",
    "            if \"assessment_results\" not in current_state:\n",
    "                current_state[\"assessment_results\"] = {}\n",
    "            \n",
    "            current_state[\"assessment_results\"][\"vulnerability\"] = {\n",
    "                \"score\": vulnerability_score,\n",
    "                \"sprinkler_assessment\": f\"Sprinklers: {'Present' if has_sprinklers else 'Absent'}, Risk level {sprinkler_score}\",\n",
    "                \"alarm_assessment\": f\"Alarm: {alarm_system}, Risk level {alarm_score}\"\n",
    "            }\n",
    "            \n",
    "            # Track completion as a list\n",
    "            if \"completed_assessments\" not in current_state:\n",
    "                current_state[\"completed_assessments\"] = []\n",
    "                \n",
    "            if \"vulnerability\" not in current_state[\"completed_assessments\"]:\n",
    "                current_state[\"completed_assessments\"].append(\"vulnerability\")\n",
    "            \n",
    "            logger.info(f\"Updated completed_assessments: {current_state['completed_assessments']}\")\n",
    "            await ctx.set(\"state\", current_state)\n",
    "            \n",
    "            logger.info(\"Vulnerability assessment completed and stored in context\")\n",
    "            return f\"Vulnerability assessment completed. Overall vulnerability score: {vulnerability_score:.1f}/5.0\"\n",
    "        \n",
    "        async def query_vulnerability_guidelines(ctx: Context, query: str) -> str:\n",
    "            \"\"\"\n",
    "            Queries the underwriting guidelines for vulnerability-related information.\n",
    "            \n",
    "            Args:\n",
    "                query: The search query for vulnerability-related guidelines\n",
    "                \n",
    "            Returns:\n",
    "                Relevant guidelines information\n",
    "            \"\"\"\n",
    "            logger.info(f\"Querying vulnerability guidelines with: {query}\")\n",
    "            \n",
    "            if self.guidelines_retriever is None:\n",
    "                return \"Guidelines retriever not available. Using default guidelines.\"\n",
    "            \n",
    "            try:\n",
    "                # Query the vector store\n",
    "                retrieval_results = self.guidelines_retriever.retrieve(query)\n",
    "                \n",
    "                # Extract and format the results\n",
    "                guidelines_info = \"\\n\\n\".join([node.text for node in retrieval_results])\n",
    "                \n",
    "                # Store in context\n",
    "                current_state = await ctx.get(\"state\")\n",
    "                if \"guidelines_retrieved\" not in current_state:\n",
    "                    current_state[\"guidelines_retrieved\"] = {}\n",
    "                \n",
    "                current_state[\"guidelines_retrieved\"][\"vulnerability\"] = guidelines_info\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"Successfully retrieved vulnerability guidelines\")\n",
    "                return f\"Retrieved vulnerability guidelines: {guidelines_info}\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error querying vulnerability guidelines: {str(e)}\")\n",
    "                return \"Error retrieving vulnerability guidelines. Using default assessment only.\"\n",
    "        \n",
    "        # CAT Modeling Agent Tools\n",
    "        async def evaluate_cat_modeling(ctx: Context, location_data: Dict[str, Any]) -> str:\n",
    "            \"\"\"\n",
    "            Evaluates the catastrophe risk based on location, flood zones, \n",
    "            earthquake potential, etc.\n",
    "            \n",
    "            Args:\n",
    "                location_data: Dictionary containing location details\n",
    "                \n",
    "            Returns:\n",
    "                A description of the CAT modeling assessment with score (1-5)\n",
    "            \"\"\"\n",
    "            logger.info(\"Starting CAT modeling assessment\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            \n",
    "            # In production, this would call specialized CAT modeling services\n",
    "            address = location_data.get(\"address\", \"\")\n",
    "            logger.info(f\"Analyzing location: {address}\")\n",
    "            \n",
    "            # Mock implementation - would use real data in production\n",
    "            # Simulating a flood zone and earthquake risk evaluation\n",
    "            if \"flood\" in address.lower() or \"coastal\" in address.lower():\n",
    "                flood_risk = 4.5\n",
    "            else:\n",
    "                flood_risk = 2.0\n",
    "            \n",
    "            # Simple geographic rules - would use proper services in production\n",
    "            geo_mapping = {\n",
    "                \"california\": 4.5,  # High earthquake risk\n",
    "                \"florida\": 4.0,     # Hurricane risk\n",
    "                \"texas\": 3.5,       # Multiple hazards\n",
    "                \"new york\": 3.0,\n",
    "                \"london\": 2.0,\n",
    "                \"birmingham\": 1.5,\n",
    "                \"manchester\": 2.0\n",
    "            }\n",
    "            \n",
    "            earthquake_risk = 1.0  # Default low risk\n",
    "            for region, risk in geo_mapping.items():\n",
    "                if region.lower() in address.lower():\n",
    "                    earthquake_risk = risk\n",
    "                    break\n",
    "            \n",
    "            # Calculate overall CAT score\n",
    "            cat_score = max(flood_risk, earthquake_risk)  # Taking worst-case scenario\n",
    "            logger.info(f\"Calculated CAT score: {cat_score} (flood_risk: {flood_risk}, earthquake_risk: {earthquake_risk})\")\n",
    "            \n",
    "            # Store the result\n",
    "            if \"assessment_results\" not in current_state:\n",
    "                current_state[\"assessment_results\"] = {}\n",
    "            \n",
    "            current_state[\"assessment_results\"][\"cat_modeling\"] = {\n",
    "                \"score\": cat_score,\n",
    "                \"flood_risk_assessment\": f\"Flood risk level: {flood_risk:.1f}/5.0\",\n",
    "                \"earthquake_risk_assessment\": f\"Earthquake/natural disaster risk: {earthquake_risk:.1f}/5.0\",\n",
    "                \"location_analyzed\": address\n",
    "            }\n",
    "            \n",
    "            # Track completion as a list\n",
    "            if \"completed_assessments\" not in current_state:\n",
    "                current_state[\"completed_assessments\"] = []\n",
    "                \n",
    "            if \"cat_modeling\" not in current_state[\"completed_assessments\"]:\n",
    "                current_state[\"completed_assessments\"].append(\"cat_modeling\")\n",
    "            \n",
    "            logger.info(f\"Updated completed_assessments: {current_state['completed_assessments']}\")\n",
    "            await ctx.set(\"state\", current_state)\n",
    "            \n",
    "            logger.info(\"CAT modeling assessment completed and stored in context\")\n",
    "            return f\"CAT modeling assessment completed. Overall CAT risk score: {cat_score:.1f}/5.0\"\n",
    "        \n",
    "        async def query_cat_modeling_guidelines(ctx: Context, query: str) -> str:\n",
    "            \"\"\"\n",
    "            Queries the underwriting guidelines for CAT modeling-related information.\n",
    "            \n",
    "            Args:\n",
    "                query: The search query for CAT modeling-related guidelines\n",
    "                \n",
    "            Returns:\n",
    "                Relevant guidelines information\n",
    "            \"\"\"\n",
    "            logger.info(f\"Querying CAT modeling guidelines with: {query}\")\n",
    "            \n",
    "            if self.guidelines_retriever is None:\n",
    "                return \"Guidelines retriever not available. Using default guidelines.\"\n",
    "            \n",
    "            try:\n",
    "                # Query the vector store\n",
    "                retrieval_results = self.guidelines_retriever.retrieve(query)\n",
    "                \n",
    "                # Extract and format the results\n",
    "                guidelines_info = \"\\n\\n\".join([node.text for node in retrieval_results])\n",
    "                \n",
    "                # Store in context\n",
    "                current_state = await ctx.get(\"state\")\n",
    "                if \"guidelines_retrieved\" not in current_state:\n",
    "                    current_state[\"guidelines_retrieved\"] = {}\n",
    "                \n",
    "                current_state[\"guidelines_retrieved\"][\"cat_modeling\"] = guidelines_info\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"Successfully retrieved CAT modeling guidelines\")\n",
    "                return f\"Retrieved CAT modeling guidelines: {guidelines_info}\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error querying CAT modeling guidelines: {str(e)}\")\n",
    "                return \"Error retrieving CAT modeling guidelines. Using default assessment only.\"\n",
    "        \n",
    "        # Decision Agent Tools\n",
    "        async def make_decision(ctx: Context) -> str:\n",
    "            \"\"\"\n",
    "            Checks if all assessments are complete, then analyzes results and makes a final decision.\n",
    "            If confidence is low, requests human review.\n",
    "            \n",
    "            Returns:\n",
    "                Decision outcome with explanation\n",
    "            \"\"\"\n",
    "            logger.info(\"Starting decision making process\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            \n",
    "            # Check if all assessments are complete\n",
    "            completed_assessments = current_state.get(\"completed_assessments\", [])\n",
    "            required_assessments = [\"hazard\", \"vulnerability\", \"cat_modeling\"]\n",
    "            \n",
    "            missing_assessments = [a for a in required_assessments if a not in completed_assessments]\n",
    "            \n",
    "            if missing_assessments:\n",
    "                logger.info(f\"Cannot make decision yet. Missing assessments: {missing_assessments}\")\n",
    "                return f\"Cannot make decision yet. The following assessments are still pending: {', '.join(missing_assessments)}\"\n",
    "            \n",
    "            # Check if we already have a final decision (to prevent infinite loops)\n",
    "            if current_state.get(\"decision\", {}).get(\"final\", False):\n",
    "                decision = current_state.get(\"decision\", {}).get(\"outcome\", \"UNKNOWN\")\n",
    "                reason = current_state.get(\"decision\", {}).get(\"reason\", \"No reason provided\")\n",
    "                confidence = current_state.get(\"decision\", {}).get(\"confidence\", 0.0)\n",
    "                \n",
    "                decision_messages = {\n",
    "                    \"PROCEED_TO_QUOTATION\": \"Submission approved to proceed to quotation.\",\n",
    "                    \"RECOMMEND_SURVEYOR\": \"Recommend surveyor assessment before proceeding.\",\n",
    "                    \"REJECT\": \"Submission rejected.\"\n",
    "                }\n",
    "                \n",
    "                logger.info(f\"Using existing final decision: {decision}\")\n",
    "                return f\"Final decision already made: {decision_messages.get(decision, decision)}. Reason: {reason}. Confidence: {confidence:.2f}\"\n",
    "            \n",
    "            # Continue with decision making if all assessments are complete\n",
    "            logger.info(\"All assessments are complete. Proceeding with decision making.\")\n",
    "            assessment_results = current_state.get(\"assessment_results\", {})\n",
    "            submission = current_state.get(\"submission_data\", {})\n",
    "            \n",
    "            # Gather scores from assessments\n",
    "            hazard_score = assessment_results.get(\"hazard\", {}).get(\"score\", 3.0)\n",
    "            vulnerability_score = assessment_results.get(\"vulnerability\", {}).get(\"score\", 3.0)\n",
    "            cat_score = assessment_results.get(\"cat_modeling\", {}).get(\"score\", 3.0)\n",
    "            \n",
    "            logger.info(f\"Assessment scores - Hazard: {hazard_score}, Vulnerability: {vulnerability_score}, CAT: {cat_score}\")\n",
    "            \n",
    "            # Calculate composite risk score (weighted average)\n",
    "            weights = {\n",
    "                \"hazard\": 0.4,\n",
    "                \"vulnerability\": 0.3,\n",
    "                \"cat\": 0.3\n",
    "            }\n",
    "            \n",
    "            composite_score = (\n",
    "                hazard_score * weights[\"hazard\"] +\n",
    "                vulnerability_score * weights[\"vulnerability\"] +\n",
    "                cat_score * weights[\"cat\"]\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"Calculated composite risk score: {composite_score}\")\n",
    "            \n",
    "            # Decision logic based on combined risk score\n",
    "            if composite_score <= 2.0:\n",
    "                decision = \"PROCEED_TO_QUOTATION\"\n",
    "                reason = \"Risk profile is within acceptable parameters\"\n",
    "                confidence = min(1.0, max(0.0, 1.0 - (composite_score / 5.0)))\n",
    "            elif composite_score <= 3.5:\n",
    "                decision = \"RECOMMEND_SURVEYOR\"\n",
    "                reason = \"Risk profile requires additional assessment\"\n",
    "                confidence = 0.8\n",
    "            else:\n",
    "                decision = \"REJECT\"\n",
    "                reason = \"Risk profile exceeds acceptable parameters\"\n",
    "                confidence = min(1.0, max(0.0, composite_score / 5.0 - 0.2))\n",
    "            \n",
    "            logger.info(f\"Initial decision: {decision}, Reason: {reason}, Confidence: {confidence:.2f}\")\n",
    "            \n",
    "            # Human-in-the-loop for decisions with low confidence or rejections\n",
    "            if confidence < 0.7 or decision == \"REJECT\":\n",
    "                # Check if we already received human feedback (to prevent loops)\n",
    "                if current_state.get(\"human_feedback_received\", False):\n",
    "                    logger.info(\"Human feedback was already received, using it to finalize decision\")\n",
    "                    feedback_comment = current_state.get(\"human_feedback_comment\", \"No feedback provided\")\n",
    "                else:\n",
    "                    logger.info(f\"Decision requires human review. Confidence: {confidence:.2f}\")\n",
    "                    \n",
    "                    # Request human feedback\n",
    "                    feedback_comment = await request_human_feedback(ctx, \n",
    "                        f\"Please review decision: {decision} for submission {submission.get('submission_id', 'Unknown')}. Confidence: {confidence:.2f}\")\n",
    "                    \n",
    "                    # Store the feedback\n",
    "                    current_state[\"human_feedback_received\"] = True\n",
    "                    current_state[\"human_feedback_comment\"] = feedback_comment\n",
    "                    \n",
    "                    await ctx.set(\"state\", current_state)\n",
    "                    logger.info(f\"Human feedback received: {feedback_comment}\")\n",
    "                \n",
    "                # Modify the decision based on feedback if needed\n",
    "                if \"approve\" in feedback_comment.lower() or \"proceed\" in feedback_comment.lower():\n",
    "                    # Override the decision if human approves\n",
    "                    if decision == \"REJECT\":\n",
    "                        decision = \"PROCEED_TO_QUOTATION\" \n",
    "                        reason = f\"Risk profile approved by human reviewer despite system assessment\"\n",
    "                        confidence = 0.85  # Human override increases confidence\n",
    "                        logger.info(\"Decision changed to PROCEED_TO_QUOTATION based on human feedback\")\n",
    "                elif \"surveyor\" in feedback_comment.lower() or \"survey\" in feedback_comment.lower():\n",
    "                    # Change to surveyor recommendation if that's what human suggests\n",
    "                    if decision != \"RECOMMEND_SURVEYOR\":\n",
    "                        decision = \"RECOMMEND_SURVEYOR\"\n",
    "                        reason = f\"Human reviewer recommended additional assessment\"\n",
    "                        confidence = 0.9  # Human override increases confidence\n",
    "                        logger.info(\"Decision changed to RECOMMEND_SURVEYOR based on human feedback\")\n",
    "                elif \"reject\" in feedback_comment.lower() or \"decline\" in feedback_comment.lower():\n",
    "                    # Confirm rejection if human agrees\n",
    "                    if decision != \"REJECT\":\n",
    "                        decision = \"REJECT\"\n",
    "                        reason = f\"Human reviewer recommended rejection\"\n",
    "                        confidence = 0.95  # Human override increases confidence\n",
    "                        logger.info(\"Decision changed to REJECT based on human feedback\")\n",
    "            \n",
    "            # Store the final decision\n",
    "            current_state[\"decision\"] = {\n",
    "                \"outcome\": decision,\n",
    "                \"reason\": reason,\n",
    "                \"composite_score\": composite_score,\n",
    "                \"confidence\": confidence,\n",
    "                \"requires_human_review\": confidence < 0.8,\n",
    "                \"human_reviewed\": current_state.get(\"human_feedback_received\", False),\n",
    "                \"assessment_summary\": {\n",
    "                    \"hazard_score\": hazard_score,\n",
    "                    \"vulnerability_score\": vulnerability_score,\n",
    "                    \"cat_score\": cat_score\n",
    "                },\n",
    "                \"final\": True  # Mark this decision as final to prevent loops\n",
    "            }\n",
    "            \n",
    "            await ctx.set(\"state\", current_state)\n",
    "            \n",
    "            decision_messages = {\n",
    "                \"PROCEED_TO_QUOTATION\": \"Submission approved to proceed to quotation.\",\n",
    "                \"RECOMMEND_SURVEYOR\": \"Recommend surveyor assessment before proceeding.\",\n",
    "                \"REJECT\": \"Submission rejected.\"\n",
    "            }\n",
    "            \n",
    "            logger.info(\"Decision made and stored in context\")\n",
    "            return f\"Decision: {decision_messages[decision]} Reason: {reason}. Confidence: {confidence:.2f}\"\n",
    "\n",
    "        async def query_decision_guidelines(ctx: Context, query: str) -> str:\n",
    "            \"\"\"\n",
    "            Queries the underwriting guidelines for decision-making information.\n",
    "            \n",
    "            Args:\n",
    "                query: The search query for decision-related guidelines\n",
    "                \n",
    "            Returns:\n",
    "                Relevant guidelines information\n",
    "            \"\"\"\n",
    "            logger.info(f\"Querying decision guidelines with: {query}\")\n",
    "            \n",
    "            if self.guidelines_retriever is None:\n",
    "                return \"Guidelines retriever not available. Using default guidelines.\"\n",
    "            \n",
    "            try:\n",
    "                # Query the vector store\n",
    "                retrieval_results = self.guidelines_retriever.retrieve(query)\n",
    "                \n",
    "                # Extract and format the results\n",
    "                guidelines_info = \"\\n\\n\".join([node.text for node in retrieval_results])\n",
    "                \n",
    "                # Store in context\n",
    "                current_state = await ctx.get(\"state\")\n",
    "                if \"guidelines_retrieved\" not in current_state:\n",
    "                    current_state[\"guidelines_retrieved\"] = {}\n",
    "                \n",
    "                current_state[\"guidelines_retrieved\"][\"decision\"] = guidelines_info\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"Successfully retrieved decision guidelines\")\n",
    "                return f\"Retrieved decision guidelines: {guidelines_info}\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error querying decision guidelines: {str(e)}\")\n",
    "                return \"Error retrieving decision guidelines. Using default assessment logic only.\"\n",
    "        \n",
    "        # Communication Agent Tools\n",
    "        async def send_notification(ctx: Context) -> str:\n",
    "            \"\"\"\n",
    "            Formats and sends notification email based on the decision.\n",
    "            \n",
    "            Returns:\n",
    "                Confirmation of notification sent\n",
    "            \"\"\"\n",
    "            logger.info(\"Starting notification preparation\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            decision = current_state.get(\"decision\", {})\n",
    "\n",
    "            # Check if this is a final decision\n",
    "            if not decision.get(\"final\", False):\n",
    "                return \"Cannot send notification for a non-final decision. Decision requires human review first.\"\n",
    "\n",
    "            # Get the decision outcome and reason\n",
    "            submission = current_state.get(\"submission_data\", {})\n",
    "            \n",
    "            # In production, this would use Azure Communication Services or similar\n",
    "            \n",
    "            # Format email content based on decision outcome\n",
    "            outcome = decision.get(\"outcome\", \"UNKNOWN\")\n",
    "            reason = decision.get(\"reason\", \"No reason provided\")\n",
    "            \n",
    "            logger.info(f\"Preparing notification for decision: {outcome}\")\n",
    "            \n",
    "            # Basic email templates\n",
    "            email_templates = {\n",
    "                \"PROCEED_TO_QUOTATION\": \"\"\"\n",
    "Subject: Submission {submission_id} Approved for Quotation\n",
    "\n",
    "Dear Distribution Team,\n",
    "\n",
    "The submission for {insured_name} (ID: {submission_id}) has been reviewed and approved to proceed to quotation.\n",
    "\n",
    "Risk Assessment Summary:\n",
    "- Hazard Score: {hazard_score}/5.0\n",
    "- Vulnerability Score: {vulnerability_score}/5.0\n",
    "- CAT Risk Score: {cat_score}/5.0\n",
    "\n",
    "Decision: Proceed to Quotation\n",
    "Confidence: {confidence:.0%}\n",
    "\n",
    "Please proceed with the quotation process.\n",
    "\n",
    "Regards,\n",
    "Underwriting AI Assistant\n",
    "\"\"\",\n",
    "                \"RECOMMEND_SURVEYOR\": \"\"\"\n",
    "Subject: Submission {submission_id} Requires Surveyor Assessment\n",
    "\n",
    "Dear Distribution Team,\n",
    "\n",
    "The submission for {insured_name} (ID: {submission_id}) has been reviewed and requires a surveyor assessment before proceeding.\n",
    "\n",
    "Risk Assessment Summary:\n",
    "- Hazard Score: {hazard_score}/5.0\n",
    "- Vulnerability Score: {vulnerability_score}/5.0\n",
    "- CAT Risk Score: {cat_score}/5.0\n",
    "\n",
    "Reason for surveyor recommendation: {reason}\n",
    "Confidence: {confidence:.0%}\n",
    "\n",
    "Please arrange for a risk assessment survey.\n",
    "\n",
    "Regards,\n",
    "Underwriting AI Assistant\n",
    "\"\"\",\n",
    "                \"REJECT\": \"\"\"\n",
    "Subject: Submission {submission_id} Rejected\n",
    "\n",
    "Dear Distribution Team,\n",
    "\n",
    "The submission for {insured_name} (ID: {submission_id}) has been reviewed and cannot proceed.\n",
    "\n",
    "Risk Assessment Summary:\n",
    "- Hazard Score: {hazard_score}/5.0\n",
    "- Vulnerability Score: {vulnerability_score}/5.0\n",
    "- CAT Risk Score: {cat_score}/5.0\n",
    "\n",
    "Reason for rejection: {reason}\n",
    "Confidence: {confidence:.0%}\n",
    "\n",
    "If you have additional information that might change this assessment, please provide it.\n",
    "\n",
    "Regards,\n",
    "Underwriting AI Assistant\n",
    "\"\"\"\n",
    "            }\n",
    "            \n",
    "            # Get template for current decision\n",
    "            template = email_templates.get(outcome, \"Unknown decision type\")\n",
    "            \n",
    "            # Fill in template variables\n",
    "            assessment_summary = decision.get(\"assessment_summary\", {})\n",
    "            email_content = template.format(\n",
    "                submission_id=submission.get(\"submission_id\", \"Unknown\"),\n",
    "                insured_name=submission.get(\"insured_name\", \"Unknown\"),\n",
    "                hazard_score=assessment_summary.get(\"hazard_score\", 0),\n",
    "                vulnerability_score=assessment_summary.get(\"vulnerability_score\", 0),\n",
    "                cat_score=assessment_summary.get(\"cat_score\", 0),\n",
    "                reason=reason,\n",
    "                confidence=decision.get(\"confidence\", 0.0)\n",
    "            )\n",
    "            \n",
    "            # Store the notification in the state\n",
    "            current_state[\"notification\"] = {\n",
    "                \"recipient\": \"distribution_team@company.com\",\n",
    "                \"content\": email_content,\n",
    "                \"sent\": True,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            # Mark workflow as complete\n",
    "            current_state[\"workflow_complete\"] = True\n",
    "            await ctx.set(\"state\", current_state)\n",
    "            \n",
    "            # In production, this would actually send the email\n",
    "            logger.info(f\"Email notification prepared for distribution team regarding submission {submission.get('submission_id', 'Unknown')}\")\n",
    "            \n",
    "            return f\"Notification email prepared and ready to send for decision: {outcome}\"\n",
    "        \n",
    "        # Helper function for human feedback\n",
    "        # Create the agents\n",
    "        self.hazard_agent = FunctionAgent(\n",
    "            name=\"HazardClassificationAgent\",\n",
    "            description=\"Evaluates the hazard classification of properties based on building type, construction, and occupancy.\",\n",
    "            system_prompt=(\n",
    "                \"You are a specialist in evaluating property hazard classifications for insurance purposes. \"\n",
    "                \"You analyze building types, construction materials, and occupancy types to determine the risk level. \"\n",
    "                \"First, query the underwriting guidelines for hazard-related criteria. \"\n",
    "                \"Then, evaluate the submission using both the guidelines and your standard assessment criteria. \"\n",
    "                \"Be thorough and precise in your assessments, using standard insurance industry criteria. \"\n",
    "                \"After completing your assessment, hand off to the VulnerabilityAssessmentAgent.\"\n",
    "            ),\n",
    "            llm=self.llm,\n",
    "            tools=[evaluate_hazard_classification, query_hazard_guidelines],\n",
    "            can_handoff_to=[\"VulnerabilityAssessmentAgent\"]\n",
    "        )\n",
    "\n",
    "        self.vulnerability_agent = FunctionAgent(\n",
    "            name=\"VulnerabilityAssessmentAgent\",\n",
    "            description=\"Evaluates property vulnerability based on security systems and protective measures.\",\n",
    "            system_prompt=(\n",
    "                \"You are a specialist in evaluating property vulnerabilities for insurance purposes. \"\n",
    "                \"You assess security systems, fire protection measures, and other safety features to determine the risk level. \"\n",
    "                \"First, query the underwriting guidelines for vulnerability-related criteria. \"\n",
    "                \"Then, evaluate the submission using both the guidelines and your standard vulnerability assessment. \"\n",
    "                \"Be thorough in considering all protective measures and their effectiveness. \"\n",
    "                \"After completing your assessment, hand off to the CATModelingAgent.\"\n",
    "            ),\n",
    "            llm=self.llm,\n",
    "            tools=[evaluate_vulnerability, query_vulnerability_guidelines],\n",
    "            can_handoff_to=[\"CATModelingAgent\"]\n",
    "        )\n",
    "\n",
    "        self.cat_modeling_agent = FunctionAgent(\n",
    "            name=\"CATModelingAgent\",\n",
    "            description=\"Evaluates catastrophe risks based on geographical location and environmental factors.\",\n",
    "            system_prompt=(\n",
    "                \"You are a specialist in catastrophe risk modeling for insurance purposes. \"\n",
    "                \"You analyze geographical locations to assess risks from natural disasters like floods, earthquakes, and storms. \"\n",
    "                \"First, query the underwriting guidelines for catastrophe risk-related criteria. \"\n",
    "                \"Then, evaluate the location using both the guidelines and standard geographical risk assessment. \"\n",
    "                \"Use precise geographical data and historical patterns to determine risk levels. \"\n",
    "                \"After completing your assessment, hand off to the DecisionAgent.\"\n",
    "            ),\n",
    "            llm=self.llm,\n",
    "            tools=[evaluate_cat_modeling, query_cat_modeling_guidelines],\n",
    "            can_handoff_to=[\"DecisionAgent\"]\n",
    "        )\n",
    "\n",
    "        self.decision_agent = FunctionAgent(\n",
    "            name=\"DecisionAgent\",\n",
    "            description=\"Analyzes all assessment results and makes the final underwriting decision.\",\n",
    "            system_prompt=(\n",
    "                \"You are a decision specialist for insurance underwriting. \"\n",
    "                \"You analyze assessment results from multiple domains to determine whether to proceed with quotation, \"\n",
    "                \"recommend a surveyor, or reject a submission. \"\n",
    "                \"First, check that all required assessments (hazard, vulnerability, cat modeling) have been completed. \"\n",
    "                \"Then, query the underwriting guidelines for decision criteria. \"\n",
    "                \"Combine the assessment results with the guidelines to make a comprehensive decision. \"\n",
    "                \"Balance all risk factors to make the most appropriate decision. \"\n",
    "                \"For low confidence decisions or rejections, request human review. \"\n",
    "                \"After making your decision, hand off to the CommunicationAgent.\"\n",
    "            ),\n",
    "            llm=self.llm,\n",
    "            tools=[make_decision, query_decision_guidelines],\n",
    "            can_handoff_to=[\"CommunicationAgent\"]\n",
    "        )\n",
    "\n",
    "        self.communication_agent = FunctionAgent(\n",
    "            name=\"CommunicationAgent\",\n",
    "            description=\"Formats and sends notifications based on the underwriting decision.\",\n",
    "            system_prompt=(\n",
    "                \"You are a communication specialist for insurance operations. \"\n",
    "                \"You create clear, appropriate notifications to inform stakeholders about underwriting decisions. \"\n",
    "                \"Ensure all relevant information is included in the appropriate format. \"\n",
    "                \"After sending the notification, the decision process is complete.\"\n",
    "            ),\n",
    "            llm=self.llm,\n",
    "            tools=[send_notification]\n",
    "        )\n",
    "        \n",
    "        # Helper function for human feedback\n",
    "        async def request_human_feedback(ctx: Context, question: str = \"\") -> str:\n",
    "            \"\"\"\n",
    "            Requests human feedback using LlamaIndex's event system.\n",
    "            \n",
    "            Args:\n",
    "                ctx: Context object\n",
    "                question: Question to ask the human reviewer\n",
    "                \n",
    "            Returns:\n",
    "                Human feedback response\n",
    "            \"\"\"\n",
    "            logger.info(f\"Requesting human feedback: {question}\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            \n",
    "            # Get decision and submission details for context\n",
    "            decision = current_state.get(\"decision\", {})\n",
    "            submission = current_state.get(\"submission_data\", {})\n",
    "            assessment_results = current_state.get(\"assessment_results\", {})\n",
    "            \n",
    "            # Get relevant guidelines information\n",
    "            guidelines_info = current_state.get(\"guidelines_retrieved\", {}).get(\"decision\", \"No specific guidelines retrieved\")\n",
    "            \n",
    "            # Create a detailed prompt for the human reviewer\n",
    "            detailed_question = f\"\"\"\n",
    "HUMAN REVIEW REQUIRED:\n",
    "{question}\n",
    "\n",
    "Submission: {submission.get('submission_id')} - {submission.get('insured_name')}\n",
    "Property: {submission.get('property_details', {}).get('building_type')} at {submission.get('property_details', {}).get('address')}\n",
    "\n",
    "Assessment Results:\n",
    "- Hazard: {assessment_results.get('hazard', {}).get('score', 0)}/5.0\n",
    "- Vulnerability: {assessment_results.get('vulnerability', {}).get('score', 0)}/5.0\n",
    "- CAT Risk: {assessment_results.get('cat_modeling', {}).get('score', 0)}/5.0\n",
    "\n",
    "System Decision: {decision.get('outcome', 'Unknown')}\n",
    "Reason: {decision.get('reason', 'No reason provided')}\n",
    "Confidence: {decision.get('confidence', 0):.0%}\n",
    "\n",
    "Relevant Guidelines:\n",
    "{guidelines_info}\n",
    "\n",
    "Please review and provide feedback. Type 'approve' to confirm the decision, or provide specific guidance:\n",
    "\"\"\"\n",
    "            \n",
    "            # Use LlamaIndex's wait_for_event to get human input\n",
    "            response = await ctx.wait_for_event(\n",
    "                HumanResponseEvent,\n",
    "                waiter_id=question,\n",
    "                waiter_event=InputRequiredEvent(\n",
    "                    prefix=detailed_question,\n",
    "                    user_name=\"Underwriter\",\n",
    "                ),\n",
    "                requirements={\"user_name\": \"Underwriter\"},\n",
    "            )\n",
    "            \n",
    "            # Record the feedback in the state\n",
    "            if \"human_feedback\" not in current_state:\n",
    "                current_state[\"human_feedback\"] = {}\n",
    "            \n",
    "            current_state[\"human_feedback\"][\"requested\"] = True\n",
    "            current_state[\"human_feedback\"][\"timestamp\"] = datetime.now().isoformat()\n",
    "            current_state[\"human_feedback\"][\"comment\"] = response.response\n",
    "            current_state[\"human_feedback\"][\"status\"] = \"completed\"\n",
    "            \n",
    "            await ctx.set(\"state\", current_state)\n",
    "            \n",
    "            return response.response\n",
    "    \n",
    "    def create_workflow(self, submission_data: Dict[str, Any]) -> AgentWorkflow:\n",
    "        \"\"\"\n",
    "        Create the workflow with all agents\n",
    "        \n",
    "        Args:\n",
    "            submission_data: The insurance submission data to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            AgentWorkflow object ready to run\n",
    "        \"\"\"\n",
    "        # Create the workflow with the 4 essential agents\n",
    "        workflow = AgentWorkflow(\n",
    "            agents=[\n",
    "                self.hazard_agent,\n",
    "                self.vulnerability_agent,\n",
    "                self.cat_modeling_agent,\n",
    "                self.decision_agent,\n",
    "                self.communication_agent\n",
    "            ],\n",
    "            # Start with hazard agent\n",
    "            root_agent=self.hazard_agent.name,\n",
    "            initial_state={\n",
    "                \"submission_data\": submission_data,\n",
    "                \"assessment_results\": {},\n",
    "                \"completed_assessments\": [],\n",
    "                \"guidelines_retrieved\": {},\n",
    "                \"decision\": {},\n",
    "                \"notification\": {},\n",
    "                \"workflow_complete\": False\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Agent workflow created successfully\")\n",
    "        return workflow\n",
    "    \n",
    "    async def run_workflow(self, submission_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run the multi-agent workflow with human-in-the-loop capability\n",
    "        \n",
    "        Args:\n",
    "            submission_data: The insurance submission data to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            The final state after workflow completion\n",
    "        \"\"\"\n",
    "        workflow = self.create_workflow(submission_data)\n",
    "        \n",
    "        logger.info(\"Starting workflow execution...\")\n",
    "        \n",
    "        # Run the workflow with a more explicit message\n",
    "        handler = workflow.run(\n",
    "            user_msg=(\n",
    "                \"Please process this insurance submission through the full assessment workflow. \"\n",
    "                \"For each step, first query the relevant underwriting guidelines, then perform your assessment. \"\n",
    "                \"Begin with the hazard classification, then evaluate vulnerability, \"\n",
    "                \"perform CAT modeling, make a decision, and finally send the appropriate notification.\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Stream the output to see progress\n",
    "        current_agent = None\n",
    "        \n",
    "        async for event in handler.stream_events():\n",
    "            # Check if workflow is complete after each step\n",
    "            current_state = await handler.ctx.get(\"state\")\n",
    "            if current_state.get(\"workflow_complete\", False):\n",
    "                logger.info(\"Workflow has been marked as complete, stopping further processing.\")\n",
    "                break\n",
    "                \n",
    "            if hasattr(event, \"current_agent_name\") and event.current_agent_name != current_agent:\n",
    "                current_agent = event.current_agent_name\n",
    "                logger.info(f\"==== Agent: {current_agent} ====\")\n",
    "                \n",
    "            # Handle human input requests\n",
    "            if isinstance(event, InputRequiredEvent):\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(\"\\nHUMAN REVIEW REQUIRED\")\n",
    "                print(\"=\"*50)\n",
    "                user_input = input(event.prefix + \"\\n> \")\n",
    "                print(\"=\"*50 + \"\\n\")\n",
    "                \n",
    "                # Send the human response back to the workflow\n",
    "                handler.ctx.send_event(\n",
    "                    HumanResponseEvent(\n",
    "                        response=user_input,\n",
    "                        user_name=event.user_name,\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            # Check if a final decision has been made\n",
    "            if current_state.get(\"decision\", {}).get(\"final\", False) and current_agent == \"CommunicationAgent\":\n",
    "                logger.info(\"Final decision has been made and notification sent. Workflow will complete.\")\n",
    "                current_state[\"workflow_complete\"] = True\n",
    "                await handler.ctx.set(\"state\", current_state)\n",
    "        \n",
    "        # Get the final state\n",
    "        final_state = await handler.ctx.get(\"state\")\n",
    "        \n",
    "        # Log the results\n",
    "        logger.info(\"Workflow execution completed.\")\n",
    "        logger.info(f\"Decision: {final_state.get('decision', {}).get('outcome', 'No decision')}\")\n",
    "        logger.info(f\"Reason: {final_state.get('decision', {}).get('reason', 'No reason provided')}\")\n",
    "        \n",
    "        # Return the final state\n",
    "        return final_state\n",
    "    \n",
    "    def summarize_results(self, final_state: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Generate a human-readable summary of the workflow results\n",
    "        \n",
    "        Args:\n",
    "            final_state: The final state after workflow completion\n",
    "            \n",
    "        Returns:\n",
    "            Formatted string with summary information\n",
    "        \"\"\"\n",
    "        decision = final_state.get(\"decision\", {})\n",
    "        submission = final_state.get(\"submission_data\", {})\n",
    "        \n",
    "        summary = []\n",
    "        summary.append(\"\\n====== INSURANCE SUBMISSION ASSESSMENT RESULTS ======\")\n",
    "        summary.append(f\"Submission ID: {submission.get('submission_id', 'Unknown')}\")\n",
    "        summary.append(f\"Insured: {submission.get('insured_name', 'Unknown')}\")\n",
    "        \n",
    "        summary.append(\"\\nCOMPLETED ASSESSMENTS:\")\n",
    "        completed = \", \".join(final_state.get(\"completed_assessments\", []))\n",
    "        summary.append(f\"- {completed}\")\n",
    "        \n",
    "        summary.append(\"\\nRISK ASSESSMENT SUMMARY:\")\n",
    "        assessment_summary = decision.get(\"assessment_summary\", {})\n",
    "        summary.append(f\"- Hazard Score: {assessment_summary.get('hazard_score', 0):.1f}/5.0\")\n",
    "        summary.append(f\"- Vulnerability Score: {assessment_summary.get('vulnerability_score', 0):.1f}/5.0\")\n",
    "        summary.append(f\"- CAT Risk Score: {assessment_summary.get('cat_score', 0):.1f}/5.0\")\n",
    "        \n",
    "        summary.append(f\"\\nDECISION: {decision.get('outcome', 'Unknown')}\")\n",
    "        summary.append(f\"Reason: {decision.get('reason', 'No reason provided')}\")\n",
    "        summary.append(f\"Confidence: {decision.get('confidence', 0):.0%}\")\n",
    "        \n",
    "        # Show human feedback if available\n",
    "        human_feedback = final_state.get(\"human_feedback\", {})\n",
    "        if human_feedback:\n",
    "            summary.append(\"\\nHUMAN FEEDBACK:\")\n",
    "            summary.append(f\"Status: {human_feedback.get('status', 'Not provided')}\")\n",
    "            summary.append(f\"Comment: {human_feedback.get('comment', 'No comment')}\")\n",
    "        \n",
    "        summary.append(\"\\n===========================================\")\n",
    "        \n",
    "        return \"\\n\".join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 15:19:32,509 - InsuranceAgentSystem - INFO - LLM and embedding models initialized\n",
      "2025-04-17 15:19:32,791 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:19:32,793 - InsuranceAgentSystem - INFO - Guidelines vector store initialized successfully\n",
      "2025-04-17 15:19:32,798 - InsuranceAgentSystem - INFO - Agent workflow created successfully\n",
      "2025-04-17 15:19:32,798 - InsuranceAgentSystem - INFO - Starting workflow execution...\n",
      "2025-04-17 15:19:32,828 - InsuranceAgentSystem - INFO - ==== Agent: HazardClassificationAgent ====\n",
      "2025-04-17 15:19:34,242 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:19:34,296 - InsuranceAgentSystem - INFO - Querying hazard guidelines with: hazard classification criteria for manufacturing buildings\n",
      "2025-04-17 15:19:34,335 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:19:34,350 - InsuranceAgentSystem - INFO - Successfully retrieved hazard guidelines\n",
      "2025-04-17 15:19:34,351 - InsuranceAgentSystem - INFO - Starting hazard classification assessment\n",
      "2025-04-17 15:19:34,352 - InsuranceAgentSystem - INFO - Analyzing property: Manufacturing building with Steel Frame with Brick construction\n",
      "2025-04-17 15:19:34,353 - InsuranceAgentSystem - INFO - Calculated hazard score: 2.5\n",
      "2025-04-17 15:19:34,353 - InsuranceAgentSystem - INFO - Updated completed_assessments: ['hazard']\n",
      "2025-04-17 15:19:34,354 - InsuranceAgentSystem - INFO - Hazard assessment completed and stored in context\n",
      "2025-04-17 15:19:34,664 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:19:42,022 - InsuranceAgentSystem - INFO - ==== Agent: VulnerabilityAssessmentAgent ====\n",
      "2025-04-17 15:19:43,390 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:19:43,435 - InsuranceAgentSystem - INFO - Querying vulnerability guidelines with: vulnerability assessment criteria for manufacturing buildings\n",
      "2025-04-17 15:19:43,504 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:19:43,506 - InsuranceAgentSystem - INFO - Successfully retrieved vulnerability guidelines\n",
      "2025-04-17 15:19:43,508 - InsuranceAgentSystem - INFO - Starting vulnerability assessment\n",
      "2025-04-17 15:19:43,509 - InsuranceAgentSystem - INFO - Security features: Sprinklers=True, Alarm=Grade A - 24hr Monitored\n",
      "2025-04-17 15:19:43,510 - InsuranceAgentSystem - INFO - Calculated vulnerability score: 1.0\n",
      "2025-04-17 15:19:43,510 - InsuranceAgentSystem - INFO - Updated completed_assessments: ['hazard', 'vulnerability']\n",
      "2025-04-17 15:19:43,510 - InsuranceAgentSystem - INFO - Vulnerability assessment completed and stored in context\n",
      "2025-04-17 15:19:43,779 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:19:49,907 - InsuranceAgentSystem - INFO - ==== Agent: CATModelingAgent ====\n",
      "2025-04-17 15:19:51,530 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:19:51,577 - InsuranceAgentSystem - INFO - Querying CAT modeling guidelines with: catastrophe risk-related criteria for manufacturing buildings\n",
      "2025-04-17 15:19:51,667 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:19:51,670 - InsuranceAgentSystem - INFO - Successfully retrieved CAT modeling guidelines\n",
      "2025-04-17 15:19:51,671 - InsuranceAgentSystem - INFO - Starting CAT modeling assessment\n",
      "2025-04-17 15:19:51,672 - InsuranceAgentSystem - INFO - Analyzing location: 123 Industrial Way, Birmingham, B6 4BD\n",
      "2025-04-17 15:19:51,673 - InsuranceAgentSystem - INFO - Calculated CAT score: 2.0 (flood_risk: 2.0, earthquake_risk: 1.5)\n",
      "2025-04-17 15:19:51,673 - InsuranceAgentSystem - INFO - Updated completed_assessments: ['hazard', 'vulnerability', 'cat_modeling']\n",
      "2025-04-17 15:19:51,674 - InsuranceAgentSystem - INFO - CAT modeling assessment completed and stored in context\n",
      "2025-04-17 15:19:52,217 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:20:00,041 - InsuranceAgentSystem - INFO - ==== Agent: DecisionAgent ====\n",
      "2025-04-17 15:20:00,473 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:20:00,498 - InsuranceAgentSystem - INFO - Starting decision making process\n",
      "2025-04-17 15:20:00,498 - InsuranceAgentSystem - INFO - All assessments are complete. Proceeding with decision making.\n",
      "2025-04-17 15:20:00,499 - InsuranceAgentSystem - INFO - Assessment scores - Hazard: 2.5, Vulnerability: 1.0, CAT: 2.0\n",
      "2025-04-17 15:20:00,500 - InsuranceAgentSystem - INFO - Calculated composite risk score: 1.9\n",
      "2025-04-17 15:20:00,500 - InsuranceAgentSystem - INFO - Initial decision: PROCEED_TO_QUOTATION, Reason: Risk profile is within acceptable parameters, Confidence: 0.62\n",
      "2025-04-17 15:20:00,501 - InsuranceAgentSystem - INFO - Decision requires human review. Confidence: 0.62\n",
      "2025-04-17 15:20:00,501 - InsuranceAgentSystem - INFO - Requesting human feedback: Please review decision: PROCEED_TO_QUOTATION for submission SUB20250417001. Confidence: 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\n",
      "HUMAN REVIEW REQUIRED\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 15:21:52,723 - InsuranceAgentSystem - INFO - Human feedback received: Why the decision is uknown?\n",
      "2025-04-17 15:21:52,724 - InsuranceAgentSystem - INFO - Decision made and stored in context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 15:21:53,394 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:21:53,593 - InsuranceAgentSystem - INFO - ==== Agent: CommunicationAgent ====\n",
      "2025-04-17 15:21:53,593 - InsuranceAgentSystem - INFO - Final decision has been made and notification sent. Workflow will complete.\n",
      "2025-04-17 15:21:54,009 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-17 15:21:54,012 - InsuranceAgentSystem - INFO - Workflow has been marked as complete, stopping further processing.\n",
      "2025-04-17 15:21:54,013 - InsuranceAgentSystem - INFO - Workflow execution completed.\n",
      "2025-04-17 15:21:54,014 - InsuranceAgentSystem - INFO - Decision: PROCEED_TO_QUOTATION\n",
      "2025-04-17 15:21:54,014 - InsuranceAgentSystem - INFO - Reason: Risk profile is within acceptable parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== INSURANCE SUBMISSION ASSESSMENT RESULTS ======\n",
      "Submission ID: SUB20250417001\n",
      "Insured: Acme Manufacturing Ltd\n",
      "\n",
      "COMPLETED ASSESSMENTS:\n",
      "- hazard, vulnerability, cat_modeling\n",
      "\n",
      "RISK ASSESSMENT SUMMARY:\n",
      "- Hazard Score: 2.5/5.0\n",
      "- Vulnerability Score: 1.0/5.0\n",
      "- CAT Risk Score: 2.0/5.0\n",
      "\n",
      "DECISION: PROCEED_TO_QUOTATION\n",
      "Reason: Risk profile is within acceptable parameters\n",
      "Confidence: 62%\n",
      "\n",
      "HUMAN FEEDBACK:\n",
      "Status: completed\n",
      "Comment: Why the decision is uknown?\n",
      "\n",
      "===========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 15:21:54,033 - InsuranceAgentSystem - INFO - Starting notification preparation\n",
      "2025-04-17 15:21:54,033 - InsuranceAgentSystem - INFO - Preparing notification for decision: PROCEED_TO_QUOTATION\n",
      "2025-04-17 15:21:54,034 - InsuranceAgentSystem - INFO - Email notification prepared for distribution team regarding submission SUB20250417001\n",
      "2025-04-17 15:21:54,590 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "async def main():\n",
    "    \"\"\"Run the insurance agent system with example data\"\"\"\n",
    "    \n",
    "    # Example submission data\n",
    "    example_submission = {\n",
    "        \"submission_id\": \"SUB20250417001\",\n",
    "        \"broker_name\": \"ABC Insurance Brokers\",\n",
    "        \"insured_name\": \"Acme Manufacturing Ltd\",\n",
    "        \"property_details\": {\n",
    "            \"address\": \"123 Industrial Way, Birmingham, B6 4BD\",\n",
    "            \"building_type\": \"Manufacturing\",\n",
    "            \"construction\": \"Steel Frame with Brick\",\n",
    "            \"year_built\": 1995,\n",
    "            \"area_sqm\": 5000,\n",
    "            \"stories\": 2,\n",
    "            \"occupancy\": \"Light Manufacturing - Electronics\",\n",
    "            \"sprinklers\": True,\n",
    "            \"alarm_system\": \"Grade A - 24hr Monitored\"\n",
    "        },\n",
    "        \"coverage\": {\n",
    "            \"building_value\": 4500000.00,\n",
    "            \"contents_value\": 2000000.00,\n",
    "            \"business_interruption\": 3000000.00,\n",
    "            \"deductible\": 25000.00\n",
    "        },\n",
    "        \"client_history\": {\n",
    "            \"claims_count\": 1,\n",
    "            \"previous_policies\": 2,\n",
    "            \"risk_score\": 68\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Initialize the system\n",
    "    system = InsuranceAgentSystem()\n",
    "    \n",
    "    # Run the workflow\n",
    "    final_state = await system.run_workflow(example_submission)\n",
    "    \n",
    "    # Print summary\n",
    "    print(system.summarize_results(final_state))\n",
    "    \n",
    "    return final_state\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
