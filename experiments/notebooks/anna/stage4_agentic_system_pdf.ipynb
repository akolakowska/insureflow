{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import asyncio\n",
    "import nest_asyncio  # Important for running asyncio in Jupyter notebooks\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# LlamaIndex imports\n",
    "from llama_index.core import Settings, VectorStoreIndex, Document, StorageContext, load_index_from_storage\n",
    "\n",
    "from llama_index.core.agent.workflow import FunctionAgent, AgentWorkflow\n",
    "from llama_index.core.workflow import Context, InputRequiredEvent, HumanResponseEvent\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.readers.file import PDFReader\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment criteria loaded successfully.\n",
      "Guidelines retriever loaded successfully.\n",
      "Assessment criteria loaded successfully.\n",
      "Guidelines retriever loaded successfully.\n",
      "Assessment tools loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import the component notebooks\n",
    "%run \"./assessment_criteria.ipynb\"\n",
    "%run \"./guidelines_helper.ipynb\"\n",
    "%run \"./assessment_tools.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply nest_asyncio to allow asyncio to work in Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"InsuranceAgentSystem\")\n",
    "\n",
    "# Environment variables - in production, load these from environment\n",
    "AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY', 'your-api-key')\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT', 'your-endpoint')\n",
    "AZURE_GPT_API_VERSION = os.getenv('AZURE_GPT_API_VERSION', '2025-01-01-preview')\n",
    "AZURE_EMBEDDING_API_VERSION = os.getenv('AZURE_EMBEDDING_API_VERSION', '2023-12-01-preview')\n",
    "\n",
    "class InsuranceAgentSystem:\n",
    "    \"\"\"Main class for the Insurance Agent System implementing Stage 4 (Rank or Reject)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the system with LLM, embeddings and guidelines\"\"\"\n",
    "        self.setup_llm_and_embeddings()\n",
    "        self.setup_guidelines_vector_store()\n",
    "        self.create_agents()\n",
    "        \n",
    "    def setup_llm_and_embeddings(self):\n",
    "        \"\"\"Configure the LLM and embedding models\"\"\"\n",
    "        self.llm = AzureOpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            deployment_name=\"gpt-4o\",\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            api_version=AZURE_GPT_API_VERSION,\n",
    "            temperature=0.1,  # Lower temperature for consistent decisions\n",
    "            timeout=60,\n",
    "        )\n",
    "        \n",
    "        self.embed_model = AzureOpenAIEmbedding(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            deployment_name=\"text-embedding-ada-002\",\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            api_version=AZURE_EMBEDDING_API_VERSION,\n",
    "        )\n",
    "        \n",
    "        # Set as default models\n",
    "        Settings.llm = self.llm\n",
    "        Settings.embed_model = self.embed_model\n",
    "        \n",
    "        logger.info(\"LLM and embedding models initialized\")\n",
    "    \n",
    "    def setup_guidelines_vector_store(self):\n",
    "        \"\"\"Initialize the guidelines vector store from the PDF\"\"\"\n",
    "        try:\n",
    "            # Define paths\n",
    "            pdf_path = \"data/UW Commercial Insurance Manual.pdf\"\n",
    "            persist_dir = \"storage/guidelines_index\"\n",
    "            \n",
    "            # Check if index already exists\n",
    "            if os.path.exists(persist_dir) and os.listdir(persist_dir):\n",
    "                logger.info(f\"Loading existing index from {persist_dir}\")\n",
    "                storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "                self.guidelines_index = load_index_from_storage(storage_context, index_cls=VectorStoreIndex)\n",
    "            else:\n",
    "                # Load and process PDF if needed\n",
    "                logger.info(f\"Loading PDF document from {pdf_path}\")\n",
    "                pdf_reader = PDFReader()\n",
    "                documents = pdf_reader.load_data(pdf_path)\n",
    "                logger.info(f\"Loaded {len(documents)} documents from PDF\")\n",
    "                \n",
    "                # Configure settings with node parser\n",
    "                Settings.node_parser = SentenceSplitter(\n",
    "                    chunk_size=1024,\n",
    "                    chunk_overlap=200,\n",
    "                    separator=\" \",\n",
    "                    paragraph_separator=\"\\n\\n\",\n",
    "                )\n",
    "                \n",
    "                # Create index\n",
    "                logger.info(\"Creating vector store index...\")\n",
    "                self.guidelines_index = VectorStoreIndex.from_documents(documents)\n",
    "                logger.info(\"Successfully created index\")\n",
    "                \n",
    "                # Persist the index\n",
    "                os.makedirs(persist_dir, exist_ok=True)\n",
    "                logger.info(f\"Persisting index to {persist_dir}\")\n",
    "                self.guidelines_index.storage_context.persist(persist_dir=persist_dir)\n",
    "                logger.info(\"Successfully persisted index\")\n",
    "            \n",
    "            # Create retriever\n",
    "            self.guidelines_retriever = self.guidelines_index.as_retriever(similarity_top_k=3)\n",
    "\n",
    "            # Initialize the specialized retrievers and assessment tools\n",
    "            self.guidelines_helper = GuidelinesRetriever(self.guidelines_retriever)\n",
    "            self.assessment_tools = AssessmentTools(self.guidelines_helper)\n",
    "            \n",
    "            logger.info(\"Guidelines vector store and assessment tools initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error setting up guidelines vector store: {str(e)}\")\n",
    "            import traceback\n",
    "            logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "            self.guidelines_index = None\n",
    "            self.guidelines_retriever = None\n",
    "            self.guidelines_helper = None\n",
    "            self.assessment_tools = None\n",
    "            logger.warning(\"Using mock guidelines data as fallback\")\n",
    "    \n",
    "    def create_agents(self):\n",
    "        \"\"\"Create all the specialized agents for the workflow\"\"\"\n",
    "        # The actual agent creation happens at the end of this method to keep all tools in scope\n",
    "        # Create all the agents with their tools\n",
    "        \n",
    "               # Hazard Agent Tools\n",
    "        async def evaluate_hazard_classification(ctx: Context, property_data: Dict[str, Any]) -> str:\n",
    "            \"\"\"\n",
    "            Evaluates the hazard classification of a property based on building type, \n",
    "            construction materials, and occupancy.\n",
    "            \n",
    "            Args:\n",
    "                property_data: Dictionary containing property details\n",
    "                \n",
    "            Returns:\n",
    "                A description of the hazard assessment with score (1-5)\n",
    "            \"\"\"\n",
    "            logger.info(\"Starting hazard classification assessment\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            \n",
    "            try:\n",
    "                # Use the assessment tools to evaluate hazard\n",
    "                if hasattr(self, 'assessment_tools') and self.assessment_tools:\n",
    "                    assessment_result = await self.assessment_tools.evaluate_hazard(property_data)\n",
    "                    hazard_score = assessment_result.get(\"score\", 3.0)\n",
    "                else:\n",
    "                    # Fallback to original logic if assessment tools aren't available\n",
    "                    building_type = property_data.get(\"building_type\", \"\")\n",
    "                    construction = property_data.get(\"construction\", \"\")\n",
    "                    occupancy = property_data.get(\"occupancy\", \"\")\n",
    "                    \n",
    "                    logger.info(f\"Analyzing property: {building_type} building with {construction} construction\")\n",
    "                    \n",
    "                    # Sample logic - would be more sophisticated in production\n",
    "                    hazard_factors = {\n",
    "                        \"building_type\": {\n",
    "                            \"Office\": 1,\n",
    "                            \"Retail\": 2,\n",
    "                            \"Manufacturing\": 3,\n",
    "                            \"Warehouse\": 3,\n",
    "                            \"Heavy Industrial\": 4,\n",
    "                            \"Nightclub\": 5\n",
    "                        },\n",
    "                        \"construction\": {\n",
    "                            \"Concrete\": 1,\n",
    "                            \"Steel Frame\": 2,\n",
    "                            \"Brick\": 2,\n",
    "                            \"Wood Frame\": 4,\n",
    "                            \"Mixed\": 3\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                    bt_score = hazard_factors[\"building_type\"].get(building_type, 3)\n",
    "                    const_score = 3  # Default score\n",
    "                    for material, score in hazard_factors[\"construction\"].items():\n",
    "                        if material.lower() in construction.lower():\n",
    "                            const_score = score\n",
    "                            break\n",
    "\n",
    "                    # Calculate overall hazard score\n",
    "                    hazard_score = (bt_score + const_score) / 2\n",
    "                    \n",
    "                    assessment_result = {\n",
    "                        \"score\": hazard_score,\n",
    "                        \"building_type_assessment\": f\"{building_type}: Risk level {bt_score}\",\n",
    "                        \"construction_assessment\": f\"{construction}: Risk level {const_score}\",\n",
    "                        \"occupancy_details\": occupancy\n",
    "                    }\n",
    "                \n",
    "                logger.info(f\"Calculated hazard score: {hazard_score}\")\n",
    "                \n",
    "                # Store the result in context\n",
    "                if \"assessment_results\" not in current_state:\n",
    "                    current_state[\"assessment_results\"] = {}\n",
    "                \n",
    "                current_state[\"assessment_results\"][\"hazard\"] = assessment_result\n",
    "                \n",
    "                # Track completion as a list\n",
    "                if \"completed_assessments\" not in current_state:\n",
    "                    current_state[\"completed_assessments\"] = []\n",
    "                    \n",
    "                if \"hazard\" not in current_state[\"completed_assessments\"]:\n",
    "                    current_state[\"completed_assessments\"].append(\"hazard\")\n",
    "                \n",
    "                logger.info(f\"Updated completed_assessments: {current_state['completed_assessments']}\")\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"Hazard assessment completed and stored in context\")\n",
    "                return f\"Hazard assessment completed. Overall hazard score: {hazard_score:.1f}/5.0\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in hazard classification: {str(e)}\")\n",
    "                return f\"Error in hazard classification: {str(e)}\"\n",
    "        \n",
    "        async def query_hazard_guidelines(ctx: Context, query: str) -> str:\n",
    "            \"\"\"\n",
    "            Queries the underwriting guidelines for hazard-related information.\n",
    "            \n",
    "            Args:\n",
    "                query: The search query for hazard-related guidelines\n",
    "                \n",
    "            Returns:\n",
    "                Relevant guidelines information\n",
    "            \"\"\"\n",
    "            logger.info(f\"Querying hazard guidelines with: {query}\")\n",
    "            \n",
    "            if not hasattr(self, 'guidelines_retriever') or self.guidelines_retriever is None:\n",
    "                return \"Guidelines retriever not available. Using default guidelines.\"\n",
    "            \n",
    "            try:\n",
    "                if hasattr(self, 'guidelines_helper') and self.guidelines_helper:\n",
    "                    building_type = \"\"\n",
    "                    construction = \"\"\n",
    "                    \n",
    "                    # Try to extract building type and construction from query\n",
    "                    if \"building\" in query.lower() and \"with\" in query.lower():\n",
    "                        parts = query.lower().split(\"with\")\n",
    "                        if len(parts) >= 2:\n",
    "                            building_parts = parts[0].split(\"for\")\n",
    "                            if len(building_parts) >= 2:\n",
    "                                building_type = building_parts[1].strip()\n",
    "                            construction = parts[1].strip()\n",
    "                    \n",
    "                    # Use enhanced guideline retrieval\n",
    "                    guidelines_info = await self.guidelines_helper.get_hazard_guidelines(\n",
    "                        building_type or query, \n",
    "                        construction or \"general\"\n",
    "                    )\n",
    "                else:\n",
    "                    # Fallback to basic retrieval\n",
    "                    retrieval_results = self.guidelines_retriever.retrieve(query)\n",
    "                    guidelines_info = \"\\n\\n\".join([node.text for node in retrieval_results])\n",
    "                \n",
    "                # Store in context\n",
    "                current_state = await ctx.get(\"state\")\n",
    "                if \"guidelines_retrieved\" not in current_state:\n",
    "                    current_state[\"guidelines_retrieved\"] = {}\n",
    "                \n",
    "                current_state[\"guidelines_retrieved\"][\"hazard\"] = guidelines_info\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"Successfully retrieved hazard guidelines\")\n",
    "                return f\"Retrieved hazard guidelines: {guidelines_info}\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error querying hazard guidelines: {str(e)}\")\n",
    "                return \"Error retrieving hazard guidelines. Using default assessment only.\"\n",
    "        \n",
    "        # Vulnerability Agent Tools\n",
    "        async def evaluate_vulnerability(ctx: Context, security_data: Dict[str, Any]) -> str:\n",
    "            \"\"\"\n",
    "            Evaluates the vulnerability of a property based on security systems,\n",
    "            protective measures, and other safety features.\n",
    "            \n",
    "            Args:\n",
    "                security_data: Dictionary containing security details\n",
    "                \n",
    "            Returns:\n",
    "                A description of the vulnerability assessment with score (1-5)\n",
    "            \"\"\"\n",
    "            logger.info(\"Starting vulnerability assessment\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            \n",
    "            try:\n",
    "                # Use the assessment tools to evaluate vulnerability\n",
    "                if hasattr(self, 'assessment_tools') and self.assessment_tools:\n",
    "                    assessment_result = await self.assessment_tools.evaluate_vulnerability(security_data)\n",
    "                    vulnerability_score = assessment_result.get(\"score\", 3.0)\n",
    "                else:\n",
    "                    # Fallback to original logic if assessment tools aren't available\n",
    "                    has_sprinklers = security_data.get(\"sprinklers\", False)\n",
    "                    alarm_system = security_data.get(\"alarm_system\", \"None\")\n",
    "                    \n",
    "                    logger.info(f\"Security features: Sprinklers={has_sprinklers}, Alarm={alarm_system}\")\n",
    "                    \n",
    "                    # Basic scoring\n",
    "                    sprinkler_score = 1 if has_sprinklers else 4\n",
    "                    \n",
    "                    alarm_scores = {\n",
    "                        \"None\": 5,\n",
    "                        \"Local\": 3,\n",
    "                        \"Monitored\": 2,\n",
    "                        \"Grade A - 24hr Monitored\": 1\n",
    "                    }\n",
    "                    alarm_score = alarm_scores.get(alarm_system, 3)\n",
    "                    \n",
    "                    # Calculate overall vulnerability score\n",
    "                    vulnerability_score = (sprinkler_score + alarm_score) / 2\n",
    "                    \n",
    "                    assessment_result = {\n",
    "                        \"score\": vulnerability_score,\n",
    "                        \"sprinkler_assessment\": f\"Sprinklers: {'Present' if has_sprinklers else 'Absent'}, Risk level {sprinkler_score}\",\n",
    "                        \"alarm_assessment\": f\"Alarm: {alarm_system}, Risk level {alarm_score}\"\n",
    "                    }\n",
    "                \n",
    "                logger.info(f\"Calculated vulnerability score: {vulnerability_score}\")\n",
    "\n",
    "                # Store the result\n",
    "                if \"assessment_results\" not in current_state:\n",
    "                    current_state[\"assessment_results\"] = {}\n",
    "                \n",
    "                current_state[\"assessment_results\"][\"vulnerability\"] = assessment_result\n",
    "                \n",
    "                # Track completion as a list\n",
    "                if \"completed_assessments\" not in current_state:\n",
    "                    current_state[\"completed_assessments\"] = []\n",
    "                    \n",
    "                if \"vulnerability\" not in current_state[\"completed_assessments\"]:\n",
    "                    current_state[\"completed_assessments\"].append(\"vulnerability\")\n",
    "                \n",
    "                logger.info(f\"Updated completed_assessments: {current_state['completed_assessments']}\")\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"Vulnerability assessment completed and stored in context\")\n",
    "                return f\"Vulnerability assessment completed. Overall vulnerability score: {vulnerability_score:.1f}/5.0\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in vulnerability assessment: {str(e)}\")\n",
    "                return f\"Error in vulnerability assessment: {str(e)}\"\n",
    "        \n",
    "        async def query_vulnerability_guidelines(ctx: Context, query: str) -> str:\n",
    "            \"\"\"\n",
    "            Queries the underwriting guidelines for vulnerability-related information.\n",
    "            \n",
    "            Args:\n",
    "                query: The search query for vulnerability-related guidelines\n",
    "                \n",
    "            Returns:\n",
    "                Relevant guidelines information\n",
    "            \"\"\"\n",
    "            logger.info(f\"Querying vulnerability guidelines with: {query}\")\n",
    "            \n",
    "            if not hasattr(self, 'guidelines_retriever') or self.guidelines_retriever is None:\n",
    "                return \"Guidelines retriever not available. Using default guidelines.\"\n",
    "            \n",
    "            try:\n",
    "                if hasattr(self, 'guidelines_helper') and self.guidelines_helper:\n",
    "                    building_type = \"\"\n",
    "                    building_age = 0\n",
    "                    \n",
    "                    # Try to extract building type and age from query\n",
    "                    if \"for\" in query.lower() and \"buildings\" in query.lower():\n",
    "                        parts = query.lower().split(\"for\")\n",
    "                        if len(parts) >= 2:\n",
    "                            building_parts = parts[1].split(\"buildings\")\n",
    "                            if len(building_parts) >= 1:\n",
    "                                building_type = building_parts[0].strip()\n",
    "                    \n",
    "                    # See if there's age info\n",
    "                    if \"years\" in query.lower():\n",
    "                        parts = query.lower().split(\"years\")\n",
    "                        if len(parts) >= 1:\n",
    "                            for word in parts[0].split()[::-1]:\n",
    "                                if word.isdigit():\n",
    "                                    building_age = int(word)\n",
    "                                    break\n",
    "                    \n",
    "                    # Use enhanced guideline retrieval\n",
    "                    guidelines_info = await self.guidelines_helper.get_vulnerability_guidelines(\n",
    "                        building_type or query, \n",
    "                        building_age or 20\n",
    "                    )\n",
    "                else:\n",
    "                    # Fallback to basic retrieval\n",
    "                    retrieval_results = self.guidelines_retriever.retrieve(query)\n",
    "                    guidelines_info = \"\\n\\n\".join([node.text for node in retrieval_results])\n",
    "                \n",
    "                # Store in context\n",
    "                current_state = await ctx.get(\"state\")\n",
    "                if \"guidelines_retrieved\" not in current_state:\n",
    "                    current_state[\"guidelines_retrieved\"] = {}\n",
    "                \n",
    "                current_state[\"guidelines_retrieved\"][\"vulnerability\"] = guidelines_info\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"Successfully retrieved vulnerability guidelines\")\n",
    "                return f\"Retrieved vulnerability guidelines: {guidelines_info}\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error querying vulnerability guidelines: {str(e)}\")\n",
    "                return \"Error retrieving vulnerability guidelines. Using default assessment only.\"\n",
    "        \n",
    "        # CAT Modeling Agent Tools\n",
    "        async def evaluate_cat_modeling(ctx: Context, location_data: Dict[str, Any]) -> str:\n",
    "            \"\"\"\n",
    "            Evaluates the catastrophe risk based on location, flood zones, \n",
    "            earthquake potential, etc.\n",
    "            \n",
    "            Args:\n",
    "                location_data: Dictionary containing location details\n",
    "                \n",
    "            Returns:\n",
    "                A description of the CAT modeling assessment with score (1-5)\n",
    "            \"\"\"\n",
    "            logger.info(\"Starting CAT modeling assessment\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            \n",
    "            try:\n",
    "                # Use the assessment tools to evaluate CAT risks\n",
    "                if hasattr(self, 'assessment_tools') and self.assessment_tools:\n",
    "                    assessment_result = await self.assessment_tools.evaluate_cat_modeling(location_data)\n",
    "                    cat_score = assessment_result.get(\"score\", 3.0)\n",
    "                else:\n",
    "                    # Fallback to original logic if assessment tools aren't available\n",
    "                    address = location_data.get(\"address\", \"\")\n",
    "                    logger.info(f\"Analyzing location: {address}\")\n",
    "                    \n",
    "                    # Mock implementation - would use real data in production\n",
    "                    # Simulating a flood zone and earthquake risk evaluation\n",
    "                    if \"flood\" in address.lower() or \"coastal\" in address.lower():\n",
    "                        flood_risk = 4.5\n",
    "                    else:\n",
    "                        flood_risk = 2.0\n",
    "                    \n",
    "                    # Simple geographic rules - would use proper services in production\n",
    "                    geo_mapping = {\n",
    "                        \"california\": 4.5,  # High earthquake risk\n",
    "                        \"florida\": 4.0,     # Hurricane risk\n",
    "                        \"texas\": 3.5,       # Multiple hazards\n",
    "                        \"new york\": 3.0,\n",
    "                        \"london\": 2.0,\n",
    "                        \"birmingham\": 1.5,\n",
    "                        \"manchester\": 2.0\n",
    "                    }\n",
    "                    \n",
    "                    earthquake_risk = 1.0  # Default low risk\n",
    "                    for region, risk in geo_mapping.items():\n",
    "                        if region.lower() in address.lower():\n",
    "                            earthquake_risk = risk\n",
    "                            break\n",
    "                    \n",
    "                    # Calculate overall CAT score\n",
    "                    cat_score = max(flood_risk, earthquake_risk)  # Taking worst-case scenario\n",
    "                    \n",
    "                    assessment_result = {\n",
    "                        \"score\": cat_score,\n",
    "                        \"flood_risk_assessment\": f\"Flood risk level: {flood_risk:.1f}/5.0\",\n",
    "                        \"earthquake_risk_assessment\": f\"Earthquake/natural disaster risk: {earthquake_risk:.1f}/5.0\",\n",
    "                        \"location_analyzed\": address\n",
    "                    }\n",
    "                \n",
    "                logger.info(f\"Calculated CAT score: {cat_score}\")\n",
    "                \n",
    "                # Store the result\n",
    "                if \"assessment_results\" not in current_state:\n",
    "                    current_state[\"assessment_results\"] = {}\n",
    "                \n",
    "                current_state[\"assessment_results\"][\"cat_modeling\"] = assessment_result\n",
    "                \n",
    "                # Track completion as a list\n",
    "                if \"completed_assessments\" not in current_state:\n",
    "                    current_state[\"completed_assessments\"] = []\n",
    "                    \n",
    "                if \"cat_modeling\" not in current_state[\"completed_assessments\"]:\n",
    "                    current_state[\"completed_assessments\"].append(\"cat_modeling\")\n",
    "                \n",
    "                logger.info(f\"Updated completed_assessments: {current_state['completed_assessments']}\")\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"CAT modeling assessment completed and stored in context\")\n",
    "                return f\"CAT modeling assessment completed. Overall CAT risk score: {cat_score:.1f}/5.0\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in CAT modeling: {str(e)}\")\n",
    "                return f\"Error in CAT modeling: {str(e)}\"\n",
    "        \n",
    "        async def query_cat_modeling_guidelines(ctx: Context, query: str) -> str:\n",
    "            \"\"\"\n",
    "            Queries the underwriting guidelines for CAT modeling-related information.\n",
    "            \n",
    "            Args:\n",
    "                query: The search query for CAT modeling-related guidelines\n",
    "                \n",
    "            Returns:\n",
    "                Relevant guidelines information\n",
    "            \"\"\"\n",
    "            logger.info(f\"Querying CAT modeling guidelines with: {query}\")\n",
    "            \n",
    "            if not hasattr(self, 'guidelines_retriever') or self.guidelines_retriever is None:\n",
    "                return \"Guidelines retriever not available. Using default guidelines.\"\n",
    "            \n",
    "            try:\n",
    "                if hasattr(self, 'guidelines_helper') and self.guidelines_helper:\n",
    "                    location = \"\"\n",
    "                    \n",
    "                    # Try to extract location from query\n",
    "                    if \"in\" in query.lower() and \"properties\" in query.lower():\n",
    "                        parts = query.lower().split(\"in\")\n",
    "                        if len(parts) >= 2:\n",
    "                            location = parts[1].strip()\n",
    "                    \n",
    "                    # Use enhanced guideline retrieval\n",
    "                    guidelines_info = await self.guidelines_helper.get_cat_modeling_guidelines(\n",
    "                        location or query\n",
    "                    )\n",
    "                else:\n",
    "                    # Fallback to basic retrieval\n",
    "                    retrieval_results = self.guidelines_retriever.retrieve(query)\n",
    "                    guidelines_info = \"\\n\\n\".join([node.text for node in retrieval_results])\n",
    "                \n",
    "                # Store in context\n",
    "                current_state = await ctx.get(\"state\")\n",
    "                if \"guidelines_retrieved\" not in current_state:\n",
    "                    current_state[\"guidelines_retrieved\"] = {}\n",
    "                \n",
    "                current_state[\"guidelines_retrieved\"][\"cat_modeling\"] = guidelines_info\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"Successfully retrieved CAT modeling guidelines\")\n",
    "                return f\"Retrieved CAT modeling guidelines: {guidelines_info}\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error querying CAT modeling guidelines: {str(e)}\")\n",
    "                return \"Error retrieving CAT modeling guidelines. Using default assessment only.\"\n",
    "        \n",
    "        async def make_decision(ctx: Context) -> str:\n",
    "            \"\"\"\n",
    "            Checks if all assessments are complete, then analyzes results and makes a final decision.\n",
    "            If confidence is low, requests human review.\n",
    "            \n",
    "            Returns:\n",
    "                Decision outcome with explanation\n",
    "            \"\"\"\n",
    "            logger.info(\"Starting decision making process\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            \n",
    "            # Check if all assessments are complete\n",
    "            completed_assessments = current_state.get(\"completed_assessments\", [])\n",
    "            required_assessments = [\"hazard\", \"vulnerability\", \"cat_modeling\"]\n",
    "            \n",
    "            missing_assessments = [a for a in required_assessments if a not in completed_assessments]\n",
    "            \n",
    "            if missing_assessments:\n",
    "                logger.info(f\"Cannot make decision yet. Missing assessments: {missing_assessments}\")\n",
    "                return f\"Cannot make decision yet. The following assessments are still pending: {', '.join(missing_assessments)}\"\n",
    "            \n",
    "            # Check if we already have a final decision (to prevent infinite loops)\n",
    "            if current_state.get(\"decision\", {}).get(\"final\", False):\n",
    "                decision = current_state.get(\"decision\", {}).get(\"outcome\", \"UNKNOWN\")\n",
    "                reason = current_state.get(\"decision\", {}).get(\"reason\", \"No reason provided\")\n",
    "                confidence = current_state.get(\"decision\", {}).get(\"confidence\", 0.0)\n",
    "                \n",
    "                decision_messages = {\n",
    "                    \"PROCEED_TO_QUOTATION\": \"Submission approved to proceed to quotation.\",\n",
    "                    \"RECOMMEND_SURVEYOR\": \"Recommend surveyor assessment before proceeding.\",\n",
    "                    \"REJECT\": \"Submission rejected.\"\n",
    "                }\n",
    "                \n",
    "                logger.info(f\"Using existing final decision: {decision}\")\n",
    "                return f\"Final decision already made: {decision_messages.get(decision, decision)}. Reason: {reason}. Confidence: {confidence:.2f}\"\n",
    "            \n",
    "            try:\n",
    "                # Continue with decision making if all assessments are complete\n",
    "                logger.info(\"All assessments are complete. Proceeding with decision making.\")\n",
    "                assessment_results = current_state.get(\"assessment_results\", {})\n",
    "                submission = current_state.get(\"submission_data\", {})\n",
    "                \n",
    "                # Use the assessment tools to make the decision if available\n",
    "                if hasattr(self, 'assessment_tools') and self.assessment_tools:\n",
    "                    decision_result = await self.assessment_tools.make_underwriting_decision(\n",
    "                        assessment_results, \n",
    "                        submission\n",
    "                    )\n",
    "                else:\n",
    "                    # Fallback to original logic if assessment tools aren't available\n",
    "                    # Gather scores from assessments\n",
    "                    hazard_score = assessment_results.get(\"hazard\", {}).get(\"score\", 3.0)\n",
    "                    vulnerability_score = assessment_results.get(\"vulnerability\", {}).get(\"score\", 3.0)\n",
    "                    cat_score = assessment_results.get(\"cat_modeling\", {}).get(\"score\", 3.0)\n",
    "                    \n",
    "                    logger.info(f\"Assessment scores - Hazard: {hazard_score}, Vulnerability: {vulnerability_score}, CAT: {cat_score}\")\n",
    "                    \n",
    "                    # Calculate composite risk score (weighted average)\n",
    "                    weights = {\n",
    "                        \"hazard\": 0.4,\n",
    "                        \"vulnerability\": 0.3,\n",
    "                        \"cat\": 0.3\n",
    "                    }\n",
    "                    \n",
    "                    composite_score = (\n",
    "                        hazard_score * weights[\"hazard\"] +\n",
    "                        vulnerability_score * weights[\"vulnerability\"] +\n",
    "                        cat_score * weights[\"cat\"]\n",
    "                    )\n",
    "                    \n",
    "                    logger.info(f\"Calculated composite risk score: {composite_score}\")\n",
    "                    \n",
    "                    # Decision logic based on combined risk score\n",
    "                    if composite_score <= 2.0:\n",
    "                        decision = \"PROCEED_TO_QUOTATION\"\n",
    "                        reason = \"Risk profile is within acceptable parameters\"\n",
    "                        confidence = min(1.0, max(0.0, 1.0 - (composite_score / 5.0)))\n",
    "                    elif composite_score <= 3.5:\n",
    "                        decision = \"RECOMMEND_SURVEYOR\"\n",
    "                        reason = \"Risk profile requires additional assessment\"\n",
    "                        confidence = 0.8\n",
    "                    else:\n",
    "                        decision = \"REJECT\"\n",
    "                        reason = \"Risk profile exceeds acceptable parameters\"\n",
    "                        confidence = min(1.0, max(0.0, composite_score / 5.0 - 0.2))\n",
    "                    \n",
    "                    decision_result = {\n",
    "                        \"outcome\": decision,\n",
    "                        \"reason\": reason,\n",
    "                        \"composite_score\": composite_score,\n",
    "                        \"confidence\": confidence,\n",
    "                        \"requires_human_review\": confidence < 0.7 or decision == \"REJECT\",\n",
    "                        \"assessment_summary\": {\n",
    "                            \"hazard_score\": hazard_score,\n",
    "                            \"vulnerability_score\": vulnerability_score,\n",
    "                            \"cat_score\": cat_score\n",
    "                        }\n",
    "                    }\n",
    "                \n",
    "                logger.info(f\"Initial decision: {decision_result['outcome']}, Reason: {decision_result['reason']}, Confidence: {decision_result['confidence']:.2f}\")\n",
    "            \n",
    "            # Human-in-the-loop for decisions with low confidence or rejections\n",
    "                if decision_result.get(\"requires_human_review\", False):\n",
    "                    # Check if we already received human feedback (to prevent loops)\n",
    "                    if current_state.get(\"human_feedback_received\", False):\n",
    "                        logger.info(\"Human feedback was already received, using it to finalize decision\")\n",
    "                        feedback_comment = current_state.get(\"human_feedback_comment\", \"No feedback provided\")\n",
    "                    else:\n",
    "                        logger.info(f\"Decision requires human review. Confidence: {decision_result.get('confidence', 0):.2f}\")\n",
    "                        \n",
    "                        # Request human feedback\n",
    "                        feedback_comment = await request_human_feedback(ctx, \n",
    "                            f\"Please review decision: {decision_result['outcome']} for submission {submission.get('submission_id', 'Unknown')}. Confidence: {decision_result.get('confidence', 0):.2f}\")\n",
    "                        \n",
    "                        # Store the feedback\n",
    "                        current_state[\"human_feedback_received\"] = True\n",
    "                        current_state[\"human_feedback_comment\"] = feedback_comment\n",
    "                        \n",
    "                        await ctx.set(\"state\", current_state)\n",
    "                        logger.info(f\"Human feedback received: {feedback_comment}\")\n",
    "                    \n",
    "                    # Modify the decision based on feedback if needed\n",
    "                    if \"approve\" in feedback_comment.lower() or \"proceed\" in feedback_comment.lower():\n",
    "                        # Override the decision if human approves\n",
    "                        if decision_result[\"outcome\"] == \"REJECT\":\n",
    "                            decision_result[\"outcome\"] = \"PROCEED_TO_QUOTATION\" \n",
    "                            decision_result[\"reason\"] = f\"Risk profile approved by human reviewer despite system assessment\"\n",
    "                            decision_result[\"confidence\"] = 0.85  # Human override increases confidence\n",
    "                            logger.info(\"Decision changed to PROCEED_TO_QUOTATION based on human feedback\")\n",
    "                    elif \"surveyor\" in feedback_comment.lower() or \"survey\" in feedback_comment.lower():\n",
    "                        # Change to surveyor recommendation if that's what human suggests\n",
    "                        if decision_result[\"outcome\"] != \"RECOMMEND_SURVEYOR\":\n",
    "                            decision_result[\"outcome\"] = \"RECOMMEND_SURVEYOR\"\n",
    "                            decision_result[\"reason\"] = f\"Human reviewer recommended additional assessment\"\n",
    "                            decision_result[\"confidence\"] = 0.9  # Human override increases confidence\n",
    "                            logger.info(\"Decision changed to RECOMMEND_SURVEYOR based on human feedback\")\n",
    "                    elif \"reject\" in feedback_comment.lower() or \"decline\" in feedback_comment.lower():\n",
    "                        # Confirm rejection if human agrees\n",
    "                        if decision_result[\"outcome\"] != \"REJECT\":\n",
    "                            decision_result[\"outcome\"] = \"REJECT\"\n",
    "                            decision_result[\"reason\"] = f\"Human reviewer recommended rejection\"\n",
    "                            decision_result[\"confidence\"] = 0.95  # Human override increases confidence\n",
    "                            logger.info(\"Decision changed to REJECT based on human feedback\")\n",
    "                \n",
    "                # Mark the decision as human reviewed and final\n",
    "                decision_result[\"human_reviewed\"] = current_state.get(\"human_feedback_received\", False)\n",
    "                decision_result[\"final\"] = True\n",
    "                \n",
    "                # Add eligibility check if using enhanced assessment\n",
    "                if hasattr(self, 'assessment_tools') and self.assessment_tools:\n",
    "                    # Check for eligibility issues based on underwriting guidelines\n",
    "                    eligibility_issues = []\n",
    "                    \n",
    "                    # Check building age\n",
    "                    building_age = datetime.now().year - submission.get(\"property_details\", {}).get(\"year_built\", 0)\n",
    "                    if building_age > 35:\n",
    "                        eligibility_issues.append(f\"Building age ({building_age} years) exceeds maximum guideline of 35 years\")\n",
    "\n",
    "                    # Check stories\n",
    "                    stories = submission.get(\"property_details\", {}).get(\"stories\", 0)\n",
    "                    has_sprinklers = submission.get(\"property_details\", {}).get(\"sprinklers\", False)\n",
    "                    max_stories = 3 if has_sprinklers else 2\n",
    "                    \n",
    "                    if stories > max_stories:\n",
    "                        eligibility_issues.append(f\"Building stories ({stories}) exceeds maximum guideline of {max_stories} stories\")\n",
    "                        \n",
    "                    # Check roof type\n",
    "                    construction = submission.get(\"property_details\", {}).get(\"construction\", \"\").lower()\n",
    "                    if \"wood shake\" in construction:\n",
    "                        eligibility_issues.append(f\"Building has ineligible roof type: wood shake\")\n",
    "                    \n",
    "                    # Modify decision if there are eligibility issues\n",
    "                    if eligibility_issues and decision_result[\"outcome\"] != \"REJECT\":\n",
    "                        decision_result[\"outcome\"] = \"RECOMMEND_SURVEYOR\" if decision_result[\"outcome\"] == \"PROCEED_TO_QUOTATION\" else decision_result[\"outcome\"]\n",
    "                        decision_result[\"reason\"] = f\"Eligibility concerns: {'; '.join(eligibility_issues[:2])}\"\n",
    "                        decision_result[\"confidence\"] = min(decision_result[\"confidence\"], 0.7)  # Lower confidence due to eligibility issues\n",
    "                        decision_result[\"eligibility_issues\"] = eligibility_issues\n",
    "                \n",
    "                # Store the final decision\n",
    "                current_state[\"decision\"] = decision_result\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                decision_messages = {\n",
    "                    \"PROCEED_TO_QUOTATION\": \"Submission approved to proceed to quotation.\",\n",
    "                    \"RECOMMEND_SURVEYOR\": \"Recommend surveyor assessment before proceeding.\",\n",
    "                    \"REJECT\": \"Submission rejected.\"\n",
    "                }\n",
    "                \n",
    "                logger.info(\"Decision made and stored in context\")\n",
    "                return f\"Decision: {decision_messages[decision_result['outcome']]} Reason: {decision_result['reason']}. Confidence: {decision_result['confidence']:.2f}\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in decision making: {str(e)}\")\n",
    "                return f\"Error in decision making: {str(e)}\"\n",
    "\n",
    "        async def query_decision_guidelines(ctx: Context, query: str) -> str:\n",
    "            \"\"\"\n",
    "            Queries the underwriting guidelines for decision-making information.\n",
    "            \n",
    "            Args:\n",
    "                query: The search query for decision-related guidelines\n",
    "                \n",
    "            Returns:\n",
    "                Relevant guidelines information\n",
    "            \"\"\"\n",
    "            logger.info(f\"Querying decision guidelines with: {query}\")\n",
    "            \n",
    "            if not hasattr(self, 'guidelines_retriever') or self.guidelines_retriever is None:\n",
    "                return \"Guidelines retriever not available. Using default guidelines.\"\n",
    "            \n",
    "            try:\n",
    "                if hasattr(self, 'guidelines_helper') and self.guidelines_helper:\n",
    "                    # Use enhanced guideline retrieval\n",
    "                    guidelines_info = await self.guidelines_helper.get_decision_guidelines()\n",
    "                else:\n",
    "                    # Fallback to basic retrieval\n",
    "                    retrieval_results = self.guidelines_retriever.retrieve(query)\n",
    "                    guidelines_info = \"\\n\\n\".join([node.text for node in retrieval_results])\n",
    "                \n",
    "                # Store in context\n",
    "                current_state = await ctx.get(\"state\")\n",
    "                if \"guidelines_retrieved\" not in current_state:\n",
    "                    current_state[\"guidelines_retrieved\"] = {}\n",
    "                \n",
    "                current_state[\"guidelines_retrieved\"][\"decision\"] = guidelines_info\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                logger.info(\"Successfully retrieved decision guidelines\")\n",
    "                return f\"Retrieved decision guidelines: {guidelines_info}\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error querying decision guidelines: {str(e)}\")\n",
    "                return \"Error retrieving decision guidelines. Using default assessment logic only.\"\n",
    "        \n",
    "        # Communication Agent Tools\n",
    "        async def send_notification(ctx: Context) -> str:\n",
    "            \"\"\"\n",
    "            Formats and sends notification email based on the decision.\n",
    "            \n",
    "            Returns:\n",
    "                Confirmation of notification sent\n",
    "            \"\"\"\n",
    "            logger.info(\"Starting notification preparation\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            decision = current_state.get(\"decision\", {})\n",
    "\n",
    "            # Check if this is a final decision\n",
    "            if not decision.get(\"final\", False):\n",
    "                return \"Cannot send notification for a non-final decision. Decision requires human review first.\"\n",
    "\n",
    "            # Get the decision outcome and reason\n",
    "            submission = current_state.get(\"submission_data\", {})\n",
    "            \n",
    "            try:\n",
    "                # Format the notification using assessment tools if available\n",
    "                if hasattr(self, 'assessment_tools') and self.assessment_tools:\n",
    "                    notification = self.assessment_tools.format_notification(decision, submission)\n",
    "                else:\n",
    "                    # Get the decision outcome and reason\n",
    "                    outcome = decision.get(\"outcome\", \"UNKNOWN\")\n",
    "                    reason = decision.get(\"reason\", \"No reason provided\")\n",
    "                    \n",
    "                    logger.info(f\"Preparing notification for decision: {outcome}\")\n",
    "                    \n",
    "                    # Basic email templates\n",
    "                    email_templates = {\n",
    "                        \"PROCEED_TO_QUOTATION\": \"\"\"\n",
    "Subject: Submission {submission_id} Approved for Quotation\n",
    "\n",
    "Dear Distribution Team,\n",
    "\n",
    "The submission for {insured_name} (ID: {submission_id}) has been reviewed and approved to proceed to quotation.\n",
    "\n",
    "Risk Assessment Summary:\n",
    "- Hazard Score: {hazard_score}/5.0\n",
    "- Vulnerability Score: {vulnerability_score}/5.0\n",
    "- CAT Risk Score: {cat_score}/5.0\n",
    "\n",
    "Decision: Proceed to Quotation\n",
    "Confidence: {confidence:.0%}\n",
    "\n",
    "Please proceed with the quotation process.\n",
    "\n",
    "Regards,\n",
    "Underwriting AI Assistant\n",
    "\"\"\",\n",
    "                        \"RECOMMEND_SURVEYOR\": \"\"\"\n",
    "Subject: Submission {submission_id} Requires Surveyor Assessment\n",
    "\n",
    "Dear Distribution Team,\n",
    "\n",
    "The submission for {insured_name} (ID: {submission_id}) has been reviewed and requires a surveyor assessment before proceeding.\n",
    "\n",
    "Risk Assessment Summary:\n",
    "- Hazard Score: {hazard_score}/5.0\n",
    "- Vulnerability Score: {vulnerability_score}/5.0\n",
    "- CAT Risk Score: {cat_score}/5.0\n",
    "\n",
    "Reason for surveyor recommendation: {reason}\n",
    "Confidence: {confidence:.0%}\n",
    "\n",
    "Please arrange for a risk assessment survey.\n",
    "\n",
    "Regards,\n",
    "Underwriting AI Assistant\n",
    "\"\"\",\n",
    "                        \"REJECT\": \"\"\"\n",
    "Subject: Submission {submission_id} Rejected\n",
    "\n",
    "Dear Distribution Team,\n",
    "\n",
    "The submission for {insured_name} (ID: {submission_id}) has been reviewed and cannot proceed.\n",
    "\n",
    "Risk Assessment Summary:\n",
    "- Hazard Score: {hazard_score}/5.0\n",
    "- Vulnerability Score: {vulnerability_score}/5.0\n",
    "- CAT Risk Score: {cat_score}/5.0\n",
    "\n",
    "Reason for rejection: {reason}\n",
    "Confidence: {confidence:.0%}\n",
    "\n",
    "If you have additional information that might change this assessment, please provide it.\n",
    "\n",
    "Regards,\n",
    "Underwriting AI Assistant\n",
    "\"\"\"\n",
    "                    }\n",
    "                    \n",
    "                    # Get template for current decision\n",
    "                    template = email_templates.get(outcome, \"Unknown decision type\")\n",
    "                    \n",
    "                    # Fill in template variables\n",
    "                    assessment_summary = decision.get(\"assessment_summary\", {})\n",
    "                    email_content = template.format(\n",
    "                        submission_id=submission.get(\"submission_id\", \"Unknown\"),\n",
    "                        insured_name=submission.get(\"insured_name\", \"Unknown\"),\n",
    "                        hazard_score=assessment_summary.get(\"hazard_score\", 0),\n",
    "                        vulnerability_score=assessment_summary.get(\"vulnerability_score\", 0),\n",
    "                        cat_score=assessment_summary.get(\"cat_score\", 0),\n",
    "                        reason=reason,\n",
    "                        confidence=decision.get(\"confidence\", 0.0)\n",
    "                    )\n",
    "                    \n",
    "                    notification = {\n",
    "                        \"recipient\": \"distribution_team@company.com\",\n",
    "                        \"content\": email_content,\n",
    "                        \"sent\": True,\n",
    "                        \"timestamp\": datetime.now().isoformat()\n",
    "                    }\n",
    "                \n",
    "                # Include eligibility issues if present\n",
    "                if decision.get(\"eligibility_issues\") and \"content\" in notification:\n",
    "                    eligibility_issues = decision.get(\"eligibility_issues\", [])\n",
    "                    eligibility_section = \"\\nEligibility Issues:\\n\" + \"\\n\".join([f\"- {issue}\" for issue in eligibility_issues])\n",
    "                    notification[\"content\"] = notification[\"content\"].replace(\"Regards,\", eligibility_section + \"\\n\\nRegards,\")\n",
    "                \n",
    "                # Store the notification in the state\n",
    "                current_state[\"notification\"] = notification\n",
    "                \n",
    "                # Mark workflow as complete\n",
    "                current_state[\"workflow_complete\"] = True\n",
    "                await ctx.set(\"state\", current_state)\n",
    "                \n",
    "                # In production, this would actually send the email\n",
    "                logger.info(f\"Email notification prepared for distribution team regarding submission {submission.get('submission_id', 'Unknown')}\")\n",
    "                \n",
    "                return f\"Notification email prepared and ready to send for decision: {decision.get('outcome', 'Unknown')}\"\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error preparing notification: {str(e)}\")\n",
    "                return f\"Error preparing notification: {str(e)}\"\n",
    "        \n",
    "        # Helper function for human feedback\n",
    "        async def request_human_feedback(ctx: Context, question: str = \"\") -> str:\n",
    "            \"\"\"\n",
    "            Requests human feedback using LlamaIndex's event system.\n",
    "            \n",
    "            Args:\n",
    "                ctx: Context object\n",
    "                question: Question to ask the human reviewer\n",
    "                \n",
    "            Returns:\n",
    "                Human feedback response\n",
    "            \"\"\"\n",
    "            logger.info(f\"Requesting human feedback: {question}\")\n",
    "            current_state = await ctx.get(\"state\")\n",
    "            \n",
    "            # Get decision and submission details for context\n",
    "            decision = current_state.get(\"decision\", {})\n",
    "            submission = current_state.get(\"submission_data\", {})\n",
    "            assessment_results = current_state.get(\"assessment_results\", {})\n",
    "            \n",
    "            # Get relevant guidelines information\n",
    "            guidelines_info = current_state.get(\"guidelines_retrieved\", {}).get(\"decision\", \"No specific guidelines retrieved\")\n",
    "            \n",
    "            # Add eligibility issues if present\n",
    "            eligibility_issues_text = \"\"\n",
    "            if decision.get(\"eligibility_issues\"):\n",
    "                eligibility_issues_text = \"\\nEligibility Issues:\\n\" + \"\\n\".join([f\"- {issue}\" for issue in decision.get(\"eligibility_issues\", [])])\n",
    "            \n",
    "            # Create a detailed prompt for the human reviewer\n",
    "            detailed_question = f\"\"\"\n",
    "HUMAN REVIEW REQUIRED:\n",
    "{question}\n",
    "\n",
    "Submission: {submission.get('submission_id')} - {submission.get('insured_name')}\n",
    "Property: {submission.get('property_details', {}).get('building_type')} at {submission.get('property_details', {}).get('address')}\n",
    "\n",
    "Assessment Results:\n",
    "- Hazard: {assessment_results.get('hazard', {}).get('score', 0)}/5.0\n",
    "- Vulnerability: {assessment_results.get('vulnerability', {}).get('score', 0)}/5.0\n",
    "- CAT Risk: {assessment_results.get('cat_modeling', {}).get('score', 0)}/5.0\n",
    "- Composite Score: {decision.get('composite_score', 0):.1f}/5.0{eligibility_issues_text}\n",
    "\n",
    "System Decision: {decision.get('outcome', 'Unknown')}\n",
    "Reason: {decision.get('reason', 'No reason provided')}\n",
    "Confidence: {decision.get('confidence', 0):.0%}\n",
    "\n",
    "Relevant Guidelines:\n",
    "{guidelines_info}\n",
    "\n",
    "Please review and provide feedback. Type 'approve' to confirm the decision, or provide specific guidance:\n",
    "\"\"\"\n",
    "            \n",
    "            # Use LlamaIndex's wait_for_event to get human input\n",
    "            response = await ctx.wait_for_event(\n",
    "                HumanResponseEvent,\n",
    "                waiter_id=question,\n",
    "                waiter_event=InputRequiredEvent(\n",
    "                    prefix=detailed_question,\n",
    "                    user_name=\"Underwriter\",\n",
    "                ),\n",
    "                requirements={\"user_name\": \"Underwriter\"},\n",
    "            )\n",
    "            \n",
    "            # Record the feedback in the state\n",
    "            if \"human_feedback\" not in current_state:\n",
    "                current_state[\"human_feedback\"] = {}\n",
    "            \n",
    "            current_state[\"human_feedback\"][\"requested\"] = True\n",
    "            current_state[\"human_feedback\"][\"timestamp\"] = datetime.now().isoformat()\n",
    "            current_state[\"human_feedback\"][\"comment\"] = response.response\n",
    "            current_state[\"human_feedback\"][\"status\"] = \"completed\"\n",
    "            \n",
    "            await ctx.set(\"state\", current_state)\n",
    "            \n",
    "            return response.response\n",
    "        \n",
    "        # Create the agents\n",
    "        self.hazard_agent = FunctionAgent(\n",
    "            name=\"HazardClassificationAgent\",\n",
    "            description=\"Evaluates the hazard classification of properties based on building type, construction, and occupancy.\",\n",
    "            system_prompt=(\n",
    "                \"You are a specialist in evaluating property hazard classifications for insurance purposes. \"\n",
    "                \"You analyze building types, construction materials, and occupancy types to determine the risk level. \"\n",
    "                \"First, query the underwriting guidelines for hazard-related criteria. \"\n",
    "                \"Then, evaluate the submission using both the guidelines and your standard assessment criteria. \"\n",
    "                \"Be thorough and precise in your assessments, using standard insurance industry criteria. \"\n",
    "                \"After completing your assessment, hand off to the VulnerabilityAssessmentAgent.\"\n",
    "            ),\n",
    "            llm=self.llm,\n",
    "            tools=[evaluate_hazard_classification, query_hazard_guidelines],\n",
    "            can_handoff_to=[\"VulnerabilityAssessmentAgent\"]\n",
    "        )\n",
    "\n",
    "        self.vulnerability_agent = FunctionAgent(\n",
    "            name=\"VulnerabilityAssessmentAgent\",\n",
    "            description=\"Evaluates property vulnerability based on security systems and protective measures.\",\n",
    "            system_prompt=(\n",
    "                \"You are a specialist in evaluating property vulnerabilities for insurance purposes. \"\n",
    "                \"You assess security systems, fire protection measures, and other safety features to determine the risk level. \"\n",
    "                \"First, query the underwriting guidelines for vulnerability-related criteria. \"\n",
    "                \"Then, evaluate the submission using both the guidelines and your standard vulnerability assessment. \"\n",
    "                \"Be thorough in considering all protective measures and their effectiveness. \"\n",
    "                \"After completing your assessment, hand off to the CATModelingAgent.\"\n",
    "            ),\n",
    "            llm=self.llm,\n",
    "            tools=[evaluate_vulnerability, query_vulnerability_guidelines],\n",
    "            can_handoff_to=[\"CATModelingAgent\"]\n",
    "        )\n",
    "\n",
    "        self.cat_modeling_agent = FunctionAgent(\n",
    "            name=\"CATModelingAgent\",\n",
    "            description=\"Evaluates catastrophe risks based on geographical location and environmental factors.\",\n",
    "            system_prompt=(\n",
    "                \"You are a specialist in catastrophe risk modeling for insurance purposes. \"\n",
    "                \"You analyze geographical locations to assess risks from natural disasters like floods, earthquakes, and storms. \"\n",
    "                \"First, query the underwriting guidelines for catastrophe risk-related criteria. \"\n",
    "                \"Then, evaluate the location using both the guidelines and standard geographical risk assessment. \"\n",
    "                \"Use precise geographical data and historical patterns to determine risk levels. \"\n",
    "                \"After completing your assessment, hand off to the DecisionAgent.\"\n",
    "            ),\n",
    "            llm=self.llm,\n",
    "            tools=[evaluate_cat_modeling, query_cat_modeling_guidelines],\n",
    "            can_handoff_to=[\"DecisionAgent\"]\n",
    "        )\n",
    "\n",
    "        self.decision_agent = FunctionAgent(\n",
    "            name=\"DecisionAgent\",\n",
    "            description=\"Analyzes all assessment results and makes the final underwriting decision.\",\n",
    "            system_prompt=(\n",
    "                \"You are a decision specialist for insurance underwriting. \"\n",
    "                \"You analyze assessment results from multiple domains to determine whether to proceed with quotation, \"\n",
    "                \"recommend a surveyor, or reject a submission. \"\n",
    "                \"First, check that all required assessments (hazard, vulnerability, cat modeling) have been completed. \"\n",
    "                \"Then, query the underwriting guidelines for decision criteria. \"\n",
    "                \"Combine the assessment results with the guidelines to make a comprehensive decision. \"\n",
    "                \"Balance all risk factors to make the most appropriate decision. \"\n",
    "                \"For low confidence decisions or rejections, request human review. \"\n",
    "                \"After making your decision, hand off to the CommunicationAgent.\"\n",
    "            ),\n",
    "            llm=self.llm,\n",
    "            tools=[make_decision, query_decision_guidelines],\n",
    "            can_handoff_to=[\"CommunicationAgent\"]\n",
    "        )\n",
    "\n",
    "        self.communication_agent = FunctionAgent(\n",
    "            name=\"CommunicationAgent\",\n",
    "            description=\"Formats and sends notifications based on the underwriting decision.\",\n",
    "            system_prompt=(\n",
    "                \"You are a communication specialist for insurance operations. \"\n",
    "                \"You create clear, appropriate notifications to inform stakeholders about underwriting decisions. \"\n",
    "                \"Ensure all relevant information is included in the appropriate format. \"\n",
    "                \"After sending the notification, the decision process is complete.\"\n",
    "            ),\n",
    "            llm=self.llm,\n",
    "            tools=[send_notification]\n",
    "        )\n",
    "    \n",
    "    def create_workflow(self, submission_data: Dict[str, Any]) -> AgentWorkflow:\n",
    "        \"\"\"\n",
    "        Create the workflow with all agents\n",
    "        \n",
    "        Args:\n",
    "            submission_data: The insurance submission data to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            AgentWorkflow object ready to run\n",
    "        \"\"\"\n",
    "        # Create the workflow with the 4 essential agents\n",
    "        workflow = AgentWorkflow(\n",
    "            agents=[\n",
    "                self.hazard_agent,\n",
    "                self.vulnerability_agent,\n",
    "                self.cat_modeling_agent,\n",
    "                self.decision_agent,\n",
    "                self.communication_agent\n",
    "            ],\n",
    "            # Start with hazard agent\n",
    "            root_agent=self.hazard_agent.name,\n",
    "            initial_state={\n",
    "                \"submission_data\": submission_data,\n",
    "                \"assessment_results\": {},\n",
    "                \"completed_assessments\": [],\n",
    "                \"guidelines_retrieved\": {},\n",
    "                \"decision\": {},\n",
    "                \"notification\": {},\n",
    "                \"workflow_complete\": False\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Agent workflow created successfully\")\n",
    "        return workflow\n",
    "    \n",
    "    async def run_workflow(self, submission_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run the multi-agent workflow with human-in-the-loop capability\n",
    "        \n",
    "        Args:\n",
    "            submission_data: The insurance submission data to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            The final state after workflow completion\n",
    "        \"\"\"\n",
    "        workflow = self.create_workflow(submission_data)\n",
    "        \n",
    "        logger.info(\"Starting workflow execution...\")\n",
    "        \n",
    "        # Run the workflow with a more explicit message\n",
    "        handler = workflow.run(\n",
    "            user_msg=(\n",
    "                \"Please process this insurance submission through the full assessment workflow. \"\n",
    "                \"For each step, first query the relevant underwriting guidelines, then perform your assessment. \"\n",
    "                \"Begin with the hazard classification, then evaluate vulnerability, \"\n",
    "                \"perform CAT modeling, make a decision, and finally send the appropriate notification.\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Stream the output to see progress\n",
    "        current_agent = None\n",
    "        \n",
    "        async for event in handler.stream_events():\n",
    "            # Check if workflow is complete after each step\n",
    "            current_state = await handler.ctx.get(\"state\")\n",
    "            if current_state.get(\"workflow_complete\", False):\n",
    "                logger.info(\"Workflow has been marked as complete, stopping further processing.\")\n",
    "                break\n",
    "                \n",
    "            if hasattr(event, \"current_agent_name\") and event.current_agent_name != current_agent:\n",
    "                current_agent = event.current_agent_name\n",
    "                logger.info(f\"==== Agent: {current_agent} ====\")\n",
    "                \n",
    "            # Handle human input requests\n",
    "            if isinstance(event, InputRequiredEvent):\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(\"\\nHUMAN REVIEW REQUIRED\")\n",
    "                print(\"=\"*50)\n",
    "                user_input = input(event.prefix + \"\\n> \")\n",
    "                print(\"=\"*50 + \"\\n\")\n",
    "                \n",
    "                # Send the human response back to the workflow\n",
    "                handler.ctx.send_event(\n",
    "                    HumanResponseEvent(\n",
    "                        response=user_input,\n",
    "                        user_name=event.user_name,\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            # Check if a final decision has been made\n",
    "            if current_state.get(\"decision\", {}).get(\"final\", False) and current_agent == \"CommunicationAgent\":\n",
    "                logger.info(\"Final decision has been made and notification sent. Workflow will complete.\")\n",
    "                current_state[\"workflow_complete\"] = True\n",
    "                await handler.ctx.set(\"state\", current_state)\n",
    "        \n",
    "        # Get the final state\n",
    "        final_state = await handler.ctx.get(\"state\")\n",
    "        \n",
    "        # Log the results\n",
    "        logger.info(\"Workflow execution completed.\")\n",
    "        logger.info(f\"Decision: {final_state.get('decision', {}).get('outcome', 'No decision')}\")\n",
    "        logger.info(f\"Reason: {final_state.get('decision', {}).get('reason', 'No reason provided')}\")\n",
    "        \n",
    "        # Return the final state\n",
    "        return final_state\n",
    "    \n",
    "    def summarize_results(self, final_state: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Generate a human-readable summary of the workflow results\n",
    "        \n",
    "        Args:\n",
    "            final_state: The final state after workflow completion\n",
    "            \n",
    "        Returns:\n",
    "            Formatted string with summary information\n",
    "        \"\"\"\n",
    "        decision = final_state.get(\"decision\", {})\n",
    "        submission = final_state.get(\"submission_data\", {})\n",
    "        \n",
    "        summary = []\n",
    "        summary.append(\"\\n====== INSURANCE SUBMISSION ASSESSMENT RESULTS ======\")\n",
    "        summary.append(f\"Submission ID: {submission.get('submission_id', 'Unknown')}\")\n",
    "        summary.append(f\"Insured: {submission.get('insured_name', 'Unknown')}\")\n",
    "        \n",
    "        # Add property details\n",
    "        property_details = submission.get(\"property_details\", {})\n",
    "        if property_details:\n",
    "            summary.append(f\"\\nPROPERTY DETAILS:\")\n",
    "            summary.append(f\"- Address: {property_details.get('address', 'Unknown')}\")\n",
    "            summary.append(f\"- Building Type: {property_details.get('building_type', 'Unknown')}\")\n",
    "            summary.append(f\"- Construction: {property_details.get('construction', 'Unknown')}\")\n",
    "            summary.append(f\"- Year Built: {property_details.get('year_built', 'Unknown')}\")\n",
    "            summary.append(f\"- Sprinklers: {'Yes' if property_details.get('sprinklers', False) else 'No'}\")\n",
    "        \n",
    "        summary.append(\"\\nCOMPLETED ASSESSMENTS:\")\n",
    "        completed = \", \".join(final_state.get(\"completed_assessments\", []))\n",
    "        summary.append(f\"- {completed}\")\n",
    "        \n",
    "        summary.append(\"\\nRISK ASSESSMENT SUMMARY:\")\n",
    "        assessment_summary = decision.get(\"assessment_summary\", {})\n",
    "        summary.append(f\"- Hazard Score: {assessment_summary.get('hazard_score', 0):.1f}/5.0\")\n",
    "        summary.append(f\"- Vulnerability Score: {assessment_summary.get('vulnerability_score', 0):.1f}/5.0\")\n",
    "        summary.append(f\"- CAT Risk Score: {assessment_summary.get('cat_score', 0):.1f}/5.0\")\n",
    "        summary.append(f\"- Composite Score: {decision.get('composite_score', 0):.1f}/5.0\")\n",
    "        \n",
    "        # Add eligibility issues if present\n",
    "        eligibility_issues = decision.get(\"eligibility_issues\", [])\n",
    "        if eligibility_issues:\n",
    "            summary.append(\"\\nELIGIBILITY CONCERNS:\")\n",
    "            for issue in eligibility_issues:\n",
    "                summary.append(f\"- {issue}\")\n",
    "        \n",
    "        summary.append(f\"\\nDECISION: {decision.get('outcome', 'Unknown')}\")\n",
    "        summary.append(f\"Reason: {decision.get('reason', 'No reason provided')}\")\n",
    "        summary.append(f\"Confidence: {decision.get('confidence', 0):.0%}\")\n",
    "        \n",
    "        # Show human feedback if available\n",
    "        human_feedback = final_state.get(\"human_feedback\", {})\n",
    "        if human_feedback:\n",
    "            summary.append(\"\\nHUMAN FEEDBACK:\")\n",
    "            summary.append(f\"Status: {human_feedback.get('status', 'Not provided')}\")\n",
    "            summary.append(f\"Comment: {human_feedback.get('comment', 'No comment')}\")\n",
    "        \n",
    "        # Add notification details if available\n",
    "        notification = final_state.get(\"notification\", {})\n",
    "        if notification:\n",
    "            summary.append(\"\\nNOTIFICATION STATUS:\")\n",
    "            summary.append(f\"Recipient: {notification.get('recipient', 'Unknown')}\")\n",
    "            summary.append(f\"Sent: {'Yes' if notification.get('sent', False) else 'No'}\")\n",
    "            summary.append(f\"Timestamp: {notification.get('timestamp', 'Unknown')}\")\n",
    "        \n",
    "        # Add reference to guidelines used\n",
    "        guidelines_referenced = decision.get(\"guidelines_referenced\", \"\")\n",
    "        if guidelines_referenced and len(guidelines_referenced) > 0:\n",
    "            summary.append(\"\\nREFERENCED GUIDELINES:\")\n",
    "            summary.append(f\"{guidelines_referenced[:300]}...\")\n",
    "        \n",
    "        summary.append(\"\\n===========================================\")\n",
    "        \n",
    "        return \"\\n\".join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 10:15:31,530 - InsuranceAgentSystem - INFO - LLM and embedding models initialized\n",
      "2025-04-24 10:15:31,531 - InsuranceAgentSystem - INFO - Loading existing index from storage/guidelines_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 10:15:31,732 - llama_index.core.indices.loading - INFO - Loading all indices.\n",
      "2025-04-24 10:15:31,733 - InsuranceAgentSystem - INFO - Guidelines vector store and assessment tools initialized successfully\n",
      "2025-04-24 10:15:31,737 - InsuranceAgentSystem - INFO - Agent workflow created successfully\n",
      "2025-04-24 10:15:31,737 - InsuranceAgentSystem - INFO - Starting workflow execution...\n",
      "2025-04-24 10:15:31,759 - InsuranceAgentSystem - INFO - ==== Agent: HazardClassificationAgent ====\n",
      "2025-04-24 10:15:33,559 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:33,594 - InsuranceAgentSystem - INFO - Querying hazard guidelines with: hazard classification criteria for manufacturing buildings\n",
      "2025-04-24 10:15:33,594 - InsuranceAgentSystem - INFO - Querying hazard guidelines with: hazard classification guidelines for hazard classification criteria for manufacturing buildings buildings with general construction\n",
      "2025-04-24 10:15:33,743 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:33,747 - InsuranceAgentSystem - INFO - Successfully retrieved hazard guidelines\n",
      "2025-04-24 10:15:33,747 - InsuranceAgentSystem - INFO - Successfully retrieved hazard guidelines\n",
      "2025-04-24 10:15:33,749 - InsuranceAgentSystem - INFO - Starting hazard classification assessment\n",
      "2025-04-24 10:15:33,749 - InsuranceAgentSystem - INFO - Starting hazard classification assessment\n",
      "2025-04-24 10:15:33,750 - InsuranceAgentSystem - INFO - Analyzing property: Manufacturing building with Steel Frame with Brick construction\n",
      "2025-04-24 10:15:33,750 - InsuranceAgentSystem - INFO - Querying hazard guidelines with: hazard classification guidelines for Manufacturing buildings with Steel Frame with Brick construction\n",
      "2025-04-24 10:15:33,781 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:33,784 - InsuranceAgentSystem - INFO - Successfully retrieved hazard guidelines\n",
      "2025-04-24 10:15:33,784 - InsuranceAgentSystem - INFO - Calculated hazard score: 2.7\n",
      "2025-04-24 10:15:33,784 - InsuranceAgentSystem - INFO - Calculated hazard score: 2.7\n",
      "2025-04-24 10:15:33,785 - InsuranceAgentSystem - INFO - Updated completed_assessments: ['hazard']\n",
      "2025-04-24 10:15:33,785 - InsuranceAgentSystem - INFO - Hazard assessment completed and stored in context\n",
      "2025-04-24 10:15:34,335 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:35,310 - InsuranceAgentSystem - INFO - ==== Agent: VulnerabilityAssessmentAgent ====\n",
      "2025-04-24 10:15:37,244 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:37,280 - InsuranceAgentSystem - INFO - Querying vulnerability guidelines with: vulnerability assessment criteria for manufacturing buildings\n",
      "2025-04-24 10:15:37,280 - InsuranceAgentSystem - INFO - Querying vulnerability guidelines with: vulnerability assessment criteria for manufacturing buildings 20 years old\n",
      "2025-04-24 10:15:37,311 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:37,314 - InsuranceAgentSystem - INFO - Successfully retrieved vulnerability guidelines\n",
      "2025-04-24 10:15:37,315 - InsuranceAgentSystem - INFO - Successfully retrieved vulnerability guidelines\n",
      "2025-04-24 10:15:37,316 - InsuranceAgentSystem - INFO - Starting vulnerability assessment\n",
      "2025-04-24 10:15:37,317 - InsuranceAgentSystem - INFO - Starting vulnerability assessment\n",
      "2025-04-24 10:15:37,317 - InsuranceAgentSystem - INFO - Security features: Sprinklers=True, Alarm=Grade A - 24hr Monitored\n",
      "2025-04-24 10:15:37,317 - InsuranceAgentSystem - INFO - Querying vulnerability guidelines with: vulnerability assessment criteria for Manufacturing buildings 30 years old\n",
      "2025-04-24 10:15:37,351 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:37,354 - InsuranceAgentSystem - INFO - Successfully retrieved vulnerability guidelines\n",
      "2025-04-24 10:15:37,354 - InsuranceAgentSystem - INFO - Calculated vulnerability score: 1.0\n",
      "2025-04-24 10:15:37,354 - InsuranceAgentSystem - INFO - Calculated vulnerability score: 1.0\n",
      "2025-04-24 10:15:37,355 - InsuranceAgentSystem - INFO - Updated completed_assessments: ['hazard', 'vulnerability']\n",
      "2025-04-24 10:15:37,355 - InsuranceAgentSystem - INFO - Vulnerability assessment completed and stored in context\n",
      "2025-04-24 10:15:37,797 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:38,335 - InsuranceAgentSystem - INFO - ==== Agent: CATModelingAgent ====\n",
      "2025-04-24 10:15:39,870 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:39,901 - InsuranceAgentSystem - INFO - Querying CAT modeling guidelines with: catastrophe risk assessment criteria for manufacturing buildings\n",
      "2025-04-24 10:15:39,901 - InsuranceAgentSystem - INFO - Querying CAT modeling guidelines with: catastrophe risk assessment criteria for properties in catastrophe risk assessment criteria for manufacturing buildings\n",
      "2025-04-24 10:15:39,935 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:39,938 - InsuranceAgentSystem - INFO - Successfully retrieved CAT modeling guidelines\n",
      "2025-04-24 10:15:39,938 - InsuranceAgentSystem - INFO - Successfully retrieved CAT modeling guidelines\n",
      "2025-04-24 10:15:39,939 - InsuranceAgentSystem - INFO - Starting CAT modeling assessment\n",
      "2025-04-24 10:15:39,940 - InsuranceAgentSystem - INFO - Starting CAT modeling assessment\n",
      "2025-04-24 10:15:39,940 - InsuranceAgentSystem - INFO - Analyzing location: 123 Industrial Way, Birmingham, B6 4BD\n",
      "2025-04-24 10:15:39,941 - InsuranceAgentSystem - INFO - Querying CAT modeling guidelines with: catastrophe risk assessment criteria for properties in 123 Industrial Way, Birmingham, B6 4BD\n",
      "2025-04-24 10:15:39,974 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:39,977 - InsuranceAgentSystem - INFO - Successfully retrieved CAT modeling guidelines\n",
      "2025-04-24 10:15:39,977 - InsuranceAgentSystem - INFO - Calculated CAT score: 2.0 (flood_risk: 2.0, earthquake_risk: 1.5, hurricane_risk: 1.0, wildfire_risk: 1.0)\n",
      "2025-04-24 10:15:39,977 - InsuranceAgentSystem - INFO - Calculated CAT score: 2.0\n",
      "2025-04-24 10:15:39,978 - InsuranceAgentSystem - INFO - Updated completed_assessments: ['hazard', 'vulnerability', 'cat_modeling']\n",
      "2025-04-24 10:15:39,978 - InsuranceAgentSystem - INFO - CAT modeling assessment completed and stored in context\n",
      "2025-04-24 10:15:40,509 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:41,234 - InsuranceAgentSystem - INFO - ==== Agent: DecisionAgent ====\n",
      "2025-04-24 10:15:42,153 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:42,179 - InsuranceAgentSystem - INFO - Starting decision making process\n",
      "2025-04-24 10:15:42,180 - InsuranceAgentSystem - INFO - All assessments are complete. Proceeding with decision making.\n",
      "2025-04-24 10:15:42,180 - InsuranceAgentSystem - INFO - Starting decision making process\n",
      "2025-04-24 10:15:42,181 - InsuranceAgentSystem - ERROR - Error in decision making: name 'self' is not defined\n",
      "2025-04-24 10:15:42,608 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:43,982 - InsuranceAgentSystem - INFO - ==== Agent: CommunicationAgent ====\n",
      "2025-04-24 10:15:44,407 - httpx - INFO - HTTP Request: POST https://uksouth-openai-shareable.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-04-24 10:15:44,777 - InsuranceAgentSystem - INFO - Workflow execution completed.\n",
      "2025-04-24 10:15:44,778 - InsuranceAgentSystem - INFO - Decision: No decision\n",
      "2025-04-24 10:15:44,778 - InsuranceAgentSystem - INFO - Reason: No reason provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== INSURANCE SUBMISSION ASSESSMENT RESULTS ======\n",
      "Submission ID: SUB20250417001\n",
      "Insured: Acme Manufacturing Ltd\n",
      "\n",
      "PROPERTY DETAILS:\n",
      "- Address: 123 Industrial Way, Birmingham, B6 4BD\n",
      "- Building Type: Manufacturing\n",
      "- Construction: Steel Frame with Brick\n",
      "- Year Built: 1995\n",
      "- Sprinklers: Yes\n",
      "\n",
      "COMPLETED ASSESSMENTS:\n",
      "- hazard, vulnerability, cat_modeling\n",
      "\n",
      "RISK ASSESSMENT SUMMARY:\n",
      "- Hazard Score: 0.0/5.0\n",
      "- Vulnerability Score: 0.0/5.0\n",
      "- CAT Risk Score: 0.0/5.0\n",
      "- Composite Score: 0.0/5.0\n",
      "\n",
      "DECISION: Unknown\n",
      "Reason: No reason provided\n",
      "Confidence: 0%\n",
      "\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "async def main():\n",
    "    \"\"\"Run the insurance agent system with example data\"\"\"\n",
    "    \n",
    "    # Example submission data\n",
    "    example_submission = {\n",
    "        \"submission_id\": \"SUB20250417001\",\n",
    "        \"broker_name\": \"ABC Insurance Brokers\",\n",
    "        \"insured_name\": \"Acme Manufacturing Ltd\",\n",
    "        \"property_details\": {\n",
    "            \"address\": \"123 Industrial Way, Birmingham, B6 4BD\",\n",
    "            \"building_type\": \"Manufacturing\",\n",
    "            \"construction\": \"Steel Frame with Brick\",\n",
    "            \"year_built\": 1995,\n",
    "            \"area_sqm\": 5000,\n",
    "            \"stories\": 2,\n",
    "            \"occupancy\": \"Light Manufacturing - Electronics\",\n",
    "            \"sprinklers\": True,\n",
    "            \"alarm_system\": \"Grade A - 24hr Monitored\"\n",
    "        },\n",
    "        \"coverage\": {\n",
    "            \"building_value\": 4500000.00,\n",
    "            \"contents_value\": 2000000.00,\n",
    "            \"business_interruption\": 3000000.00,\n",
    "            \"deductible\": 25000.00\n",
    "        },\n",
    "        \"client_history\": {\n",
    "            \"claims_count\": 1,\n",
    "            \"previous_policies\": 2,\n",
    "            \"risk_score\": 68\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Initialize the system\n",
    "    system = InsuranceAgentSystem()\n",
    "    \n",
    "    # Run the workflow\n",
    "    final_state = await system.run_workflow(example_submission)\n",
    "    \n",
    "    # Print summary\n",
    "    print(system.summarize_results(final_state))\n",
    "    \n",
    "    return final_state\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
