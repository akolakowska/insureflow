{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ```python\n",
    "# --- Imports and Setup (similar to section4.ipynb) ---\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Azure OpenAI Configuration ---\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "gpt_api_version = os.getenv('AZURE_GPT_API_VERSION')\n",
    "embedding_api_version = os.getenv('AZURE_EMBEDDING_API_VERSION')\n",
    "llm_deployment_name = \"gpt-4o\" # Replace with your deployment name\n",
    "embedding_deployment_name = \"text-embedding-3-small\" # Replace with your deployment name\n",
    "\n",
    "# Check if environment variables are loaded\n",
    "if not all([api_key, azure_endpoint, gpt_api_version, embedding_api_version]):\n",
    "    raise ValueError(\"Azure OpenAI environment variables not set correctly.\")\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    deployment_name=llm_deployment_name,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=gpt_api_version,\n",
    ")\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    deployment_name=embedding_deployment_name,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=embedding_api_version,\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "print(\"LLM and Embedding models initialized.\")\n",
    "\n",
    "# --- Placeholder Workflow Functions (Tools for the Supervisor) ---\n",
    "# These functions simulate running the workflows from section1-4.\n",
    "# They expect an input string like \"Submission: {...} State: {...}\"\n",
    "# They return a JSON string like {\"status\": \"...\", \"reason\": \"...\", \"new_state\": {...}}\n",
    "\n",
    "async def run_missing_value_check(input_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulates running the missing value check workflow (section1.ipynb).\n",
    "    Parses input string for submission and state. Checks if required fields exist.\n",
    "    Updates state and returns JSON result.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Missing Value Check ---\")\n",
    "    try:\n",
    "        submission_str = input_str.split(\" State: \")[0].replace(\"Submission: \", \"\")\n",
    "        state_str = input_str.split(\" State: \")[1]\n",
    "        submission_details = json.loads(submission_str)\n",
    "        current_state = json.loads(state_str)\n",
    "        print(f\"  Input State: {current_state}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error parsing input: {e}\")\n",
    "        return json.dumps({\"status\": \"error\", \"reason\": f\"Input parsing error: {e}\", \"new_state\": {}})\n",
    "\n",
    "    if current_state.get(\"missing_value_passed\", False):\n",
    "        print(\"  Check previously passed. Skipping.\")\n",
    "        return json.dumps({\"status\": \"skipped\", \"reason\": \"Previously passed\", \"new_state\": current_state})\n",
    "\n",
    "    # Simulate check: Check if 'client' exists\n",
    "    if submission_details.get(\"client\"):\n",
    "        print(\"  Check PASSED.\")\n",
    "        current_state[\"missing_value_passed\"] = True\n",
    "        return json.dumps({\"status\": \"passed\", \"reason\": \"All required values present.\", \"new_state\": current_state})\n",
    "    else:\n",
    "        print(\"  Check FAILED: 'client' field missing.\")\n",
    "        current_state[\"missing_value_passed\"] = False\n",
    "        return json.dumps({\"status\": \"failed\", \"reason\": \"'client' field missing\", \"new_state\": current_state})\n",
    "\n",
    "async def run_duplication_check(input_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulates running the duplication check workflow (section2.ipynb).\n",
    "    Parses input, checks state, simulates logic, updates state, returns JSON.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Duplication Check ---\")\n",
    "    try:\n",
    "        state_str = input_str.split(\" State: \")[1]\n",
    "        current_state = json.loads(state_str)\n",
    "        print(f\"  Input State: {current_state}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error parsing input: {e}\")\n",
    "        return json.dumps({\"status\": \"error\", \"reason\": f\"Input parsing error: {e}\", \"new_state\": current_state})\n",
    "\n",
    "    if current_state.get(\"duplication_check_passed\", False):\n",
    "        print(\"  Check previously passed. Skipping.\")\n",
    "        return json.dumps({\"status\": \"skipped\", \"reason\": \"Previously passed\", \"new_state\": current_state})\n",
    "\n",
    "    # Simulate check: Always passes in this example\n",
    "    print(\"  Check PASSED (Simulation).\")\n",
    "    current_state[\"duplication_check_passed\"] = True\n",
    "    return json.dumps({\"status\": \"passed\", \"reason\": \"No duplicate found.\", \"new_state\": current_state})\n",
    "\n",
    "\n",
    "async def run_compliance_check(input_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulates running the compliance check workflow (section3.ipynb).\n",
    "    Parses input, checks state, simulates logic (e.g., coverage amount), updates state, returns JSON.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Compliance Check ---\")\n",
    "    try:\n",
    "        submission_str = input_str.split(\" State: \")[0].replace(\"Submission: \", \"\")\n",
    "        state_str = input_str.split(\" State: \")[1]\n",
    "        submission_details = json.loads(submission_str)\n",
    "        current_state = json.loads(state_str)\n",
    "        print(f\"  Input State: {current_state}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error parsing input: {e}\")\n",
    "        return json.dumps({\"status\": \"error\", \"reason\": f\"Input parsing error: {e}\", \"new_state\": current_state})\n",
    "\n",
    "    if current_state.get(\"compliance_check_passed\", False):\n",
    "        print(\"  Check previously passed. Skipping.\")\n",
    "        return json.dumps({\"status\": \"skipped\", \"reason\": \"Previously passed\", \"new_state\": current_state})\n",
    "\n",
    "    # Simulate check: Fails if coverage > 800B IRR, passes otherwise or on resubmission\n",
    "    coverage_str = submission_details.get(\"coverage_requirements\", {}).get(\"desired_coverage_amount\", \"IRR 0\")\n",
    "    try:\n",
    "        # Handle potential formatting like \"IRR 800,000,000,000\"\n",
    "        coverage = int(''.join(filter(str.isdigit, coverage_str)))\n",
    "    except ValueError:\n",
    "        print(\"  Error parsing coverage amount.\")\n",
    "        return json.dumps({\"status\": \"error\", \"reason\": \"Invalid coverage amount format\", \"new_state\": current_state})\n",
    "\n",
    "    limit = 800_000_000_000\n",
    "    is_resubmission = current_state.get(\"resubmission\", False)\n",
    "\n",
    "    if coverage <= limit:\n",
    "        print(f\"  Check PASSED (Coverage: {coverage} <= {limit}).\")\n",
    "        current_state[\"compliance_check_passed\"] = True\n",
    "        current_state[\"compliance_issues\"] = []\n",
    "        return json.dumps({\"status\": \"passed\", \"reason\": \"Coverage within limits.\", \"new_state\": current_state})\n",
    "    else: # Coverage > limit\n",
    "        print(f\"  Check FAILED (Coverage: {coverage} > {limit}).\")\n",
    "        current_state[\"compliance_check_passed\"] = False\n",
    "        current_state[\"compliance_issues\"] = [\"Coverage amount exceeds limit\"]\n",
    "        return json.dumps({\"status\": \"failed\", \"reason\": f\"Coverage amount {coverage} exceeds limit {limit}\", \"new_state\": current_state})\n",
    "\n",
    "\n",
    "async def run_guideline_check(input_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulates running the guideline check workflow (section4.ipynb).\n",
    "    Parses input, checks state (requires compliance pass), simulates logic, updates state, returns JSON.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Running Guideline Check ---\")\n",
    "    try:\n",
    "        state_str = input_str.split(\" State: \")[1]\n",
    "        current_state = json.loads(state_str)\n",
    "        print(f\"  Input State: {current_state}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error parsing input: {e}\")\n",
    "        return json.dumps({\"status\": \"error\", \"reason\": f\"Input parsing error: {e}\", \"new_state\": current_state})\n",
    "\n",
    "    if current_state.get(\"guideline_check_passed\", False):\n",
    "        print(\"  Check previously passed. Skipping.\")\n",
    "        return json.dumps({\"status\": \"skipped\", \"reason\": \"Previously passed\", \"new_state\": current_state})\n",
    "\n",
    "    # Guideline check requires prior checks to pass\n",
    "    if not current_state.get(\"missing_value_passed\", False) or \\\n",
    "       not current_state.get(\"duplication_check_passed\", False) or \\\n",
    "       not current_state.get(\"compliance_check_passed\", False):\n",
    "        print(\"  Check SKIPPED (Due to prior check failure).\")\n",
    "        current_state[\"guideline_check_passed\"] = False # Mark as not passed\n",
    "        return json.dumps({\"status\": \"skipped\", \"reason\": \"Skipped due to prior check failure\", \"new_state\": current_state})\n",
    "    else:\n",
    "        # Simulate guideline check (assume it passes if compliance passed)\n",
    "        print(\"  Check PASSED (Simulation).\")\n",
    "        current_state[\"guideline_check_passed\"] = True\n",
    "        current_state[\"guideline_result\"] = \"All guidelines met.\"\n",
    "        # In reality, this might trigger the email agent from section4 if issues were found\n",
    "        return json.dumps({\"status\": \"passed\", \"reason\": \"Submission meets guidelines.\", \"new_state\": current_state})\n",
    "\n",
    "# --- Create Tools ---\n",
    "tools = [\n",
    "    FunctionTool.from_defaults(fn=run_missing_value_check, name=\"run_missing_value_check\"),\n",
    "    FunctionTool.from_defaults(fn=run_duplication_check, name=\"run_duplication_check\"),\n",
    "    FunctionTool.from_defaults(fn=run_compliance_check, name=\"run_compliance_check\"),\n",
    "    FunctionTool.from_defaults(fn=run_guideline_check, name=\"run_guideline_check\"),\n",
    "]\n",
    "\n",
    "# --- Supervisory Agent Definition ---\n",
    "supervisor_system_prompt = \"\"\"\n",
    "You are a supervisory agent orchestrating insurance quote checks.\n",
    "Your goal is to decide which checking workflows (tools) to run based on the submission and its current state provided in the input.\n",
    "\n",
    "Available tools: run_missing_value_check, run_duplication_check, run_compliance_check, run_guideline_check.\n",
    "Each tool takes a single string argument: 'Submission: {submission_json} State: {current_state_json}'.\n",
    "Each tool returns a JSON string: {\"status\": \"...\", \"reason\": \"...\", \"new_state\": {...}}. You MUST parse this JSON result to get the 'new_state'.\n",
    "\n",
    "Workflow Logic:\n",
    "1.  **Parse Input:** Extract the submission details (JSON) and current state (JSON) from the user prompt.\n",
    "2.  **Determine Starting Point:** Check the 'current_state'.\n",
    "    - If it's a new submission (e.g., empty state or no checks passed), start with `run_missing_value_check`.\n",
    "    - If it's a resubmission (e.g., `resubmission: true` in state) or some checks previously passed/failed, identify the FIRST check that hasn't passed (`missing_value_passed`, `duplication_check_passed`, `compliance_check_passed`, `guideline_check_passed` are all false or missing for that check and subsequent ones). Start processing from that check. Do NOT re-run checks marked as passed in the state.\n",
    "3.  **Execute Sequentially:** Run the necessary checks in the standard order: missing value -> duplication -> compliance -> guideline.\n",
    "4.  **State Update:** Before calling the *next* tool, YOU MUST update the `current_state_json` part of the tool input string using the `new_state` returned by the *previous* tool call.\n",
    "5.  **Stop on Failure:** If any check tool returns a status of \"failed\" or \"error\", stop the sequence immediately.\n",
    "6.  **Final Output:** Summarize the outcome. State which checks were run and the final status (e.g., \"All checks passed.\", \"Compliance check failed: [reason from tool output].\"). Include the final state JSON in your response.\n",
    "\"\"\"\n",
    "\n",
    "supervisor_agent = ReActAgent.from_tools(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True, # Set to True to see the agent's reasoning steps\n",
    "    system_prompt=supervisor_system_prompt,\n",
    ")\n",
    "\n",
    "# --- Simulation Runner ---\n",
    "async def run_scenario(scenario_name: str, submission_dict: dict, initial_state_dict: dict):\n",
    "    print(f\"\\n{'='*20} SCENARIO: {scenario_name} {'='*20}\")\n",
    "    input_prompt = f\"Process this submission. Submission: {json.dumps(submission_dict)} State: {json.dumps(initial_state_dict)}\"\n",
    "    print(f\"Input Prompt:\\n{input_prompt}\\n\")\n",
    "    response = await supervisor_agent.achat(input_prompt)\n",
    "    print(f\"\\nFinal Supervisor Response ({scenario_name}):\\n{response}\\n\")\n",
    "    return response\n",
    "\n",
    "# --- Define Scenarios ---\n",
    "\n",
    "# Scenario 1: New Submission (expected to fail compliance)\n",
    "new_submission_dict = {\n",
    "  \"insurance_broker\": \"Prime Insurance Brokers\", \"date\": \"25 May 2025\", \"client\": \"Parsian Evin Hotel Ltd.\",\n",
    "  \"coverage_requirements\": { \"desired_coverage_amount\": \"IRR 950,000,000,000\" } # > 800B limit\n",
    "}\n",
    "initial_state_dict_s1 = {}\n",
    "\n",
    "# Scenario 2: Resubmission after Compliance Failure (expected to pass all)\n",
    "# State reflects outcome of a previous run similar to Scenario 1\n",
    "previous_state_dict_s2 = {\n",
    "    \"missing_value_passed\": True,\n",
    "    \"duplication_check_passed\": True,\n",
    "    \"compliance_check_passed\": False, # Failed previously\n",
    "    \"compliance_issues\": [\"Coverage amount exceeds limit\"],\n",
    "    \"guideline_check_passed\": None, # Not reached\n",
    "    \"resubmission\": True # Flag for supervisor logic\n",
    "}\n",
    "corrected_submission_dict = {\n",
    "  \"insurance_broker\": \"Prime Insurance Brokers\", \"date\": \"25 May 2025\", \"client\": \"Parsian Evin Hotel Ltd.\",\n",
    "  \"coverage_requirements\": { \"desired_coverage_amount\": \"IRR 500,000,000,000\" } # Corrected amount <= 800B limit\n",
    "}\n",
    "\n",
    "# Scenario 3: New Submission (expected to pass all)\n",
    "pass_submission_dict = {\n",
    "  \"insurance_broker\": \"Prime Insurance Brokers\", \"date\": \"25 May 2025\", \"client\": \"Parsian Evin Hotel Ltd.\",\n",
    "  \"coverage_requirements\": { \"desired_coverage_amount\": \"IRR 100,000,000,000\" } # <= 800B limit\n",
    "}\n",
    "initial_state_dict_s3 = {}\n",
    "\n",
    "\n",
    "# --- Run Simulations Asynchronously ---\n",
    "async def main():\n",
    "    await run_scenario(\"New Submission - Fails Compliance\", new_submission_dict, initial_state_dict_s1)\n",
    "    await run_scenario(\"Resubmission - Corrected Compliance\", corrected_submission_dict, previous_state_dict_s2)\n",
    "    await run_scenario(\"New Submission - Passes All\", pass_submission_dict, initial_state_dict_s3)\n",
    "\n",
    "# Execute the main async function\n",
    "# In a Jupyter notebook, you might need to use await main() directly if running in an async environment\n",
    "# or asyncio.run(main()) if not.\n",
    "# await main() # Use this if running in Jupyter/IPython with top-level await enabled\n",
    "asyncio.run(main()) # Use this in a standard Python script"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
